

##### FILE: .\agents_status_report.py #####
import os
import pandas as pd

# מילון תיאורים ותיעוד לכל מודול/קובץ עיקרי, כולל תפקיד, רמת נחיצות, מה חסר לגרסת-על
# ניתן להרחיב/לעדכן ידנית בהתאם לשינויים
MANUAL_META = {
    "core/adx_score_agent.py": {
        "Role": "חישוב עוצמת מגמה (ADX) לאיתור איתותי trend, איתור עוצמת מהלך.",
        "Necessity": "ליבה",
        "Missing_for_Pro": (
            "חסר ניתוח רב-טיימפריים, אין שילוב ADX עם אינדיקטורים משלימים (ATR, Volume, RSI), "
            "אין טריגר דינמי, חסר ניהול confidence score לאיתות חזק, אין בדיקת השפעה על סיכון, "
            "חסר threshold חכם לניהול כניסה/יציאה."
        )
    },
    "core/analyst_rating_agent.py": {
        "Role": "סקירת המלצות אנליסטים, השוואת איכות תחזיות, איתור הפתעות אנליסטים.",
        "Necessity": "עזר",
        "Missing_for_Pro": (
            "אין ניתוח קונצנזוס מתקדם, חסר סטטיסטיקת שגיאות אנליסטים, לא מחשב השפעת הפתעות על תנועה, "
            "לא מחשב איכות דירוג מול ביצוע בפועל."
        )
    },
    "core/atr_score_agent.py": {
        "Role": "חישוב ATR ובדיקת תנודתיות יחסית, איתור חריגות תזמון.",
        "Necessity": "ליבה",
        "Missing_for_Pro": (
            "מחשב ATR בלבד, לא מבצע חיתוך עם סטיית תקן/עוצמת מגמה, חסר scoring חוזק תנועה, "
            "אין שילוב עם ניהול סיכונים, לא מזהה trade setup ייחודיים לפי תנודתיות."
        )
    },
    "core/support_zone_strength_detector.py": {
        "Role": "זיהוי אזורי תמיכה/התנגדות, חישוב חוזק טכני, scoring zone.",
        "Necessity": "ליבה",
        "Missing_for_Pro": (
            "אין Order Flow Analysis, חסר volume profile מתקדם (POC, Value Area), "
            "לא מזהה פעילות שחקנים גדולים, אין scoring confidence, לא מנתח false/true breakouts סטטיסטיים, "
            "לא משקלל price action/cross-validation עם דפוסים אחרים."
        )
    },
    "core/rsi_compression_sniffer.py": {
        "Role": "איתור דחיסות/קומפרסיה ב-RSI, בדיקת קצה oversold/overbought.",
        "Necessity": "עזר",
        "Missing_for_Pro": (
            "אין ניתוח multi-timeframe, לא משלב עם ווליום/תבניות מחזור, חסר threshold דינמי, "
            "לא מנתח סף סטטיסטי למחזוריות, לא מתחשב באירועים היסטוריים."
        )
    },
    "core/volume_tension_meter.py": {
        "Role": "מדידת לחצי ווליום, חיפוש Volume Squeeze/Expansion.",
        "Necessity": "ליבה",
        "Missing_for_Pro": (
            "לא מזהה Volume Squeeze/Contraction, אין cross עם Bollinger Bands, לא בודק השפעות breakout, "
            "חסר סטטיסטיקות דינמיות."
        )
    },
    "core/breakout_retest_recognizer.py": {
        "Role": "זיהוי פריצות ומבחני retest, איתור false breakouts.",
        "Necessity": "ליבה",
        "Missing_for_Pro": (
            "מזהה רק בסיס, חסר סטטיסטיקות על retest, אין ניתוח false breakout, לא מחשב quality/סיכוי הצלחה, "
            "לא מבצע קונפיג מחקרי."
        )
    },
    "core/bullish_pattern_spotter.py": {
        "Role": "זיהוי דפוסים שוריים: cup&handle, flag, VCP.",
        "Necessity": "ליבה",
        "Missing_for_Pro": (
            "חסר דפוסים מתקדמים (VCP, Triangle, Bollinger Squeeze, Pennant), אין cross עם volume pattern, "
            "לא מחשב historical hit rate."
        )
    },
    "core/float_pressure_evaluator.py": {
        "Role": "חישוב לחץ float, איתור trigger buyback/split/short interest.",
        "Necessity": "עזר",
        "Missing_for_Pro": (
            "חסר אינטגרציה עם short interest, אין scoring pressure/עוצמה, לא מזהה טריגרים מיוחדים."
        )
    },
    "core/gap_detector_ultimate.py": {
        "Role": "איתור gap&run, ניתוח חוזק gap, סינון false gap.",
        "Necessity": "עזר",
        "Missing_for_Pro": (
            "אין ניתוח volume validation, לא מחשב עוצמת gap, לא מזהה gap&run, אין תיקוף מחקרי."
        )
    },
    "core/geopolitical_risk_monitor.py": {
        "Role": "ניתוח סיכוני גאו-פוליטיקה על ניירות ערך, בדיקת השפעות macro-events.",
        "Necessity": "עזר/נדרש",
        "Missing_for_Pro": (
            "בודק רק headline/event, אין חפיפה לאירועי שוק/סקטור, לא מבצע סימולציות השפעה."
        )
    },
    "core/moving_average_pressure_bot.py": {
        "Role": "איתור לחצי MA, cross/staking, golden/death cross.",
        "Necessity": "עזר",
        "Missing_for_Pro": (
            "לא משלב cross/stacking דינמי, חסר multi-period MA, אין חיתוך עם דפוסים אחרים."
        )
    },
    "core/pattern_recognition.py": {
        "Role": "זיהוי מתקדם של דפוסים טכניים: VCP, Golden Cross, Bollinger Squeeze, Pennant.",
        "Necessity": "ליבה",
        "Missing_for_Pro": (
            "דורש זיהוי דפוסים מורכבים, scoring, תיקוף אוטומטי מול דאטה היסטורית, "
            "אין ניהול false breakout/היטמעות מול מודולים נוספים."
        )
    },
    "core/multi_agent_validator.py": {
        "Role": "ולידציה בין מספר סוכנים, זיהוי קונפליקט/חפיפות בין איתותים.",
        "Necessity": "מערכת",
        "Missing_for_Pro": (
            "לא מבצע scoring מתואם, חסר ניתוח סינרגיות/ניגודים בין סוכנים, לא כולל ניהול קונפליקט."
        )
    },
    "core/sentiment_scorer.py": {
        "Role": "מדידת סנטימנט (חדשות, רשת, אנליסטים), ניתוח עומק השפעה.",
        "Necessity": "ליבה",
        "Missing_for_Pro": (
            "לא מחשב sentiment מרשת (Reddit, FinTwit), חסר חיבור ל־ML, אין ניתוח עומק/הצלבה מול תנועה בפועל."
        )
    },
    "core/short_squeeze_potential_analyzer.py": {
        "Role": "איתור פוטנציאל short squeeze, הצלבה מול ווליום/אירועים.",
        "Necessity": "עזר",
        "Missing_for_Pro": (
            "לא משקלל Volume/Event triggers, חסר scoring cross עם float/short interest."
        )
    },
    "core/earnings_surprise_tracker.py": {
        "Role": "ניתוח הפתעות דוחות, איתור anomalies בתגובת שוק.",
        "Necessity": "עזר",
        "Missing_for_Pro": (
            "לא מחשב רצף/חזרתיות הפתעות, לא בודק השפעת surprise על מהלך מניה, "
            "לא משווה לציפיות אנליסטים."
        )
    },
    "core/growth_scanner.py": {
        "Role": "חישוב עקביות/צמיחה, זיהוי אנומליות.",
        "Necessity": "עזר",
        "Missing_for_Pro": (
            "לא מחשב variance/trend מורכב, אין חיתוך סקטור/מאקרו, חסר scoring."
        )
    },
    "core/valuation_anomaly_detector.py": {
        "Role": "איתור חריגות שווי, השוואת PE/Growth/Innovation.",
        "Necessity": "עזר",
        "Missing_for_Pro": (
            "לא מבצע חיתוך מגזר/סקטור, חסר scoring דינמי, לא משקלל גורמי חדשנות/צמיחה."
        )
    },
    # דוגמאות נוספות לסוכנים עתידיים או קבצי מערכת:
    "core/macro_trend_scanner.py": {
        "Role": "זיהוי מגמות מאקרו (GDP, FED, PMI, CPI, אינפלציה) והשפעתן על השוק.",
        "Necessity": "נדרש (חסר)",
        "Missing_for_Pro": (
            "לא קיים בפועל. דרוש שילוב API לנתוני מאקרו, ניתוח סטטיסטי, תצוגה גרפית, חיבור למנוע התראות."
        )
    },
    "core/social_media_hype_scanner.py": {
        "Role": "מדידת הייפ/סנטימנט מרשתות (Reddit, FinTwit, Stocktwits), איתור גלי hype.",
        "Necessity": "נדרש (חסר)",
        "Missing_for_Pro": (
            "לא קיים בפועל. דורש פיתוח ML לניתוח סנטימנט, אינטגרציה לאינדקסים, איתור שינוי חריג, scoring."
        )
    },
    "dashboard/main_dashboard.py": {
        "Role": "תצוגה גרפית, דוחות, התרעות, ניהול תסריטי אוטומציה, שילוב ML.",
        "Necessity": "מערכת",
        "Missing_for_Pro": (
            "חסר מנוע התראות, אין דוחות ML, לא כולל שילוב כל סוכני הליבה, אין backtesting/real-time."
        )
    },
    # ... אפשר להמשיך ולהוסיף כל קובץ/מודול/Agent לפי הצורך.
}

# בונה רשימה של כל הקבצים במערכת (כולל תתי-תיקיות)
def collect_all_files(root="."):
    all_files = []
    for dirpath, _, filenames in os.walk(root):
        for fname in filenames:
            # מוסיף רק קבצי py, ipynb, csv, json, md, txt, וגם legacy
            if fname.endswith(('.py', '.ipynb', '.csv', '.json', '.md', '.txt')):
                rel_path = os.path.join(dirpath, fname).replace("\\", "/")
                all_files.append(rel_path)
    return all_files

def get_manual_meta(path):
    if path in MANUAL_META:
        return MANUAL_META[path]
    # קובץ עזר/דוקו/דאטה/ניסוי/תשתית:
    if path.endswith(".md") or "readme" in path.lower():
        return {"Role": "תיעוד/דוקומנטציה", "Necessity": "עזר", "Missing_for_Pro": "אין צורך בפיתוח נוסף."}
    if path.endswith(".csv") or path.endswith(".json"):
        return {"Role": "דאטה/תצוגה", "Necessity": "עזר", "Missing_for_Pro": "קובץ נתונים; לא דורש גרסת על."}
    if path.endswith(".ipynb"):
        return {"Role": "ניסוי/מחקר", "Necessity": "עזר/Deprecated", "Missing_for_Pro": "קובץ ניסוי בלבד."}
    if "legacy" in path.lower():
        return {"Role": "Deprecated/ישן", "Necessity": "Deprecated", "Missing_for_Pro": "לא נדרש, אפשר למחוק."}
    return {"Role": "קובץ אחר", "Necessity": "לא מסווג", "Missing_for_Pro": "דרוש סיווג/סקירה ידנית."}

def build_report():
    files = collect_all_files(".")
    # הוספת קבצים נדרשים שלא קיימים בפועל (מתוך מחקר/תכנית עבודה)
    needed = [
        "core/macro_trend_scanner.py",
        "core/social_media_hype_scanner.py",
        "dashboard/main_dashboard.py",
        "core/news_catalyst_agent.py",
    ]
    for k in needed:
        if k not in files:
            files.append(k)
    records = []
    for path in sorted(files):
        fname = os.path.basename(path)
        meta = get_manual_meta(path)
        agent = fname.replace(".py", "")
        records.append({
            "Agent": agent,
            "Path": path,
            "Exists": os.path.exists(path),
            "Integrated": "TRUE" if meta["Necessity"] in ["ליבה", "עזר", "מערכת"] and os.path.exists(path) else "FALSE",
            "Advanced_Version": "FALSE",  # בודק לפי המילון בלבד; תוכל לסמן TRUE ידנית אחרי שדרוג
            "Role": meta["Role"],
            "Necessity": meta["Necessity"],
            "Missing_for_Pro": meta["Missing_for_Pro"],
        })
    df = pd.DataFrame(records)
    df.to_excel("agents_system_full_report.xlsx", index=False)
    print("דוח סוכנים מלא נוצר: agents_system_full_report.xlsx")

if __name__ == "__main__":
    build_report()


##### FILE: .\agent_status_report.py #####
import sys
import os
import json
import pandas as pd

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '')))
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), 'core')))
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), 'utils')))

from core.alpha_score_engine import AlphaScoreEngine
from utils import data_fetcher

SETTINGS_PATH = os.path.join(os.path.dirname(__file__), "settings.json") \
    if os.path.exists(os.path.join(os.path.dirname(__file__), "settings.json")) \
    else os.path.join(os.path.dirname(__file__), "config", "settings.json")

with open(SETTINGS_PATH, "r") as f:
    config = json.load(f)

engine = AlphaScoreEngine(config)

SYMBOLS = ["AAPL", "TSLA", "NVDA"]

def fetch_data(symbol):
    try:
        return data_fetcher.get_price_data(symbol, interval="1day", outputsize=100)
    except Exception as e:
        print(f"Error fetching price data for {symbol}: {e}")
        return None

def run_agent_report(symbol):
    price_df = fetch_data(symbol)
    if price_df is None:
        return {"symbol": symbol, "status": "NO DATA"}
    try:
        results = {}
        for agent_name, agent in engine.agents.items():
            try:
                # קריאה מותאמת פר סוכן
                if agent_name == "FloatPressureEvaluator":
                    result = agent.analyze(symbol, price_df)
                elif agent_name in [
                    "ShortSqueezePotentialAnalyzer",
                    "EarningsSurpriseTracker",
                    "GrowthConsistencyScanner",
                    "ValuationAnomalyDetector",
                    "SentimentScorer",
                    "GeopoliticalRiskMonitor"
                ]:
                    result = agent.analyze(symbol)
                else:
                    result = agent.analyze(price_df)
                results[agent_name] = (
                    "OK_TRUE" if result else "OK_FALSE"
                )
            except Exception as ex:
                print(f"[{symbol}][{agent_name}] ERROR: {type(ex).__name__} | {str(ex)}")
                results[agent_name] = f"ERROR: {type(ex).__name__} | {str(ex)}"
        return {"symbol": symbol, **results}
    except Exception as ex:
        print(f"[{symbol}] ENGINE ERROR: {type(ex).__name__} | {str(ex)}")
        return {"symbol": symbol, "status": f"ENGINE ERROR: {type(ex).__name__} | {str(ex)}"}

all_results = []
for symbol in SYMBOLS:
    row = run_agent_report(symbol)
    all_results.append(row)
    print(f"Finished {symbol}")

df = pd.DataFrame(all_results)
df.to_csv("outputs/agent_status_report.csv", index=False, encoding="utf-8-sig")
print("\n=== Agent Status Report ===")
print(df.to_string(index=False))
print("\n\nReport saved to outputs/agent_status_report.csv")


##### FILE: .\all_binary_files.txt #####


##### FILE: .\agents_system_full_report.xlsx #####
[BINARY FILE: .xlsx | BASE64 ENCODED BELOW]
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

##### FILE: .\all_text_files.txt #####


##### FILE: .\agents_status_report.py #####
import os
import pandas as pd

# מילון תיאורים ותיעוד לכל מודול/קובץ עיקרי, כולל תפקיד, רמת נחיצות, מה חסר לגרסת-על
# ניתן להרחיב/לעדכן ידנית בהתאם לשינויים
MANUAL_META = {
    "core/adx_score_agent.py": {
        "Role": "חישוב עוצמת מגמה (ADX) לאיתור איתותי trend, איתור עוצמת מהלך.",
        "Necessity": "ליבה",
        "Missing_for_Pro": (
            "חסר ניתוח רב-טיימפריים, אין שילוב ADX עם אינדיקטורים משלימים (ATR, Volume, RSI), "
            "אין טריגר דינמי, חסר ניהול confidence score לאיתות חזק, אין בדיקת השפעה על סיכון, "
            "חסר threshold חכם לניהול כניסה/יציאה."
        )
    },
    "core/analyst_rating_agent.py": {
        "Role": "סקירת המלצות אנליסטים, השוואת איכות תחזיות, איתור הפתעות אנליסטים.",
        "Necessity": "עזר",
        "Missing_for_Pro": (
            "אין ניתוח קונצנזוס מתקדם, חסר סטטיסטיקת שגיאות אנליסטים, לא מחשב השפעת הפתעות על תנועה, "
            "לא מחשב איכות דירוג מול ביצוע בפועל."
        )
    },
    "core/atr_score_agent.py": {
        "Role": "חישוב ATR ובדיקת תנודתיות יחסית, איתור חריגות תזמון.",
        "Necessity": "ליבה",
        "Missing_for_Pro": (
            "מחשב ATR בלבד, לא מבצע חיתוך עם סטיית תקן/עוצמת מגמה, חסר scoring חוזק תנועה, "
            "אין שילוב עם ניהול סיכונים, לא מזהה trade setup ייחודיים לפי תנודתיות."
        )
    },
    "core/support_zone_strength_detector.py": {
        "Role": "זיהוי אזורי תמיכה/התנגדות, חישוב חוזק טכני, scoring zone.",
        "Necessity": "ליבה",
        "Missing_for_Pro": (
            "אין Order Flow Analysis, חסר volume profile מתקדם (POC, Value Area), "
            "לא מזהה פעילות שחקנים גדולים, אין scoring confidence, לא מנתח false/true breakouts סטטיסטיים, "
            "לא משקלל price action/cross-validation עם דפוסים אחרים."
        )
    },
    "core/rsi_compression_sniffer.py": {
        "Role": "איתור דחיסות/קומפרסיה ב-RSI, בדיקת קצה oversold/overbought.",
        "Necessity": "עזר",
        "Missing_for_Pro": (
            "אין ניתוח multi-timeframe, לא משלב עם ווליום/תבניות מחזור, חסר threshold דינמי, "
            "לא מנתח סף סטטיסטי למחזוריות, לא מתחשב באירועים היסטוריים."
        )
    },
    "core/volume_tension_meter.py": {
        "Role": "מדידת לחצי ווליום, חיפוש Volume Squeeze/Expansion.",
        "Necessity": "ליבה",
        "Missing_for_Pro": (
            "לא מזהה Volume Squeeze/Contraction, אין cross עם Bollinger Bands, לא בודק השפעות breakout, "
            "חסר סטטיסטיקות דינמיות."
        )
    },
    "core/breakout_retest_recognizer.py": {
        "Role": "זיהוי פריצות ומבחני retest, איתור false breakouts.",
        "Necessity": "ליבה",
        "Missing_for_Pro": (
            "מזהה רק בסיס, חסר סטטיסטיקות על retest, אין ניתוח false breakout, לא מחשב quality/סיכוי הצלחה, "
            "לא מבצע קונפיג מחקרי."
        )
    },
    "core/bullish_pattern_spotter.py": {
        "Role": "זיהוי דפוסים שוריים: cup&handle, flag, VCP.",
        "Necessity": "ליבה",
        "Missing_for_Pro": (
            "חסר דפוסים מתקדמים (VCP, Triangle, Bollinger Squeeze, Pennant), אין cross עם volume pattern, "
            "לא מחשב historical hit rate."
        )
    },
    "core/float_pressure_evaluator.py": {
        "Role": "חישוב לחץ float, איתור trigger buyback/split/short interest.",
        "Necessity": "עזר",
        "Missing_for_Pro": (
            "חסר אינטגרציה עם short interest, אין scoring pressure/עוצמה, לא מזהה טריגרים מיוחדים."
        )
    },
    "core/gap_detector_ultimate.py": {
        "Role": "איתור gap&run, ניתוח חוזק gap, סינון false gap.",
        "Necessity": "עזר",
        "Missing_for_Pro": (
            "אין ניתוח volume validation, לא מחשב עוצמת gap, לא מזהה gap&run, אין תיקוף מחקרי."
        )
    },
    "core/geopolitical_risk_monitor.py": {
        "Role": "ניתוח סיכוני גאו-פוליטיקה על ניירות ערך, בדיקת השפעות macro-events.",
        "Necessity": "עזר/נדרש",
        "Missing_for_Pro": (
            "בודק רק headline/event, אין חפיפה לאירועי שוק/סקטור, לא מבצע סימולציות השפעה."
        )
    },
    "core/moving_average_pressure_bot.py": {
        "Role": "איתור לחצי MA, cross/staking, golden/death cross.",
        "Necessity": "עזר",
        "Missing_for_Pro": (
            "לא משלב cross/stacking דינמי, חסר multi-period MA, אין חיתוך עם דפוסים אחרים."
        )
    },
    "core/pattern_recognition.py": {
        "Role": "זיהוי מתקדם של דפוסים טכניים: VCP, Golden Cross, Bollinger Squeeze, Pennant.",
        "Necessity": "ליבה",
        "Missing_for_Pro": (
            "דורש זיהוי דפוסים מורכבים, scoring, תיקוף אוטומטי מול דאטה היסטורית, "
            "אין ניהול false breakout/היטמעות מול מודולים נוספים."
        )
    },
    "core/multi_agent_validator.py": {
        "Role": "ולידציה בין מספר סוכנים, זיהוי קונפליקט/חפיפות בין איתותים.",
        "Necessity": "מערכת",
        "Missing_for_Pro": (
            "לא מבצע scoring מתואם, חסר ניתוח סינרגיות/ניגודים בין סוכנים, לא כולל ניהול קונפליקט."
        )
    },
    "core/sentiment_scorer.py": {
        "Role": "מדידת סנטימנט (חדשות, רשת, אנליסטים), ניתוח עומק השפעה.",
        "Necessity": "ליבה",
        "Missing_for_Pro": (
            "לא מחשב sentiment מרשת (Reddit, FinTwit), חסר חיבור ל־ML, אין ניתוח עומק/הצלבה מול תנועה בפועל."
        )
    },
    "core/short_squeeze_potential_analyzer.py": {
        "Role": "איתור פוטנציאל short squeeze, הצלבה מול ווליום/אירועים.",
        "Necessity": "עזר",
        "Missing_for_Pro": (
            "לא משקלל Volume/Event triggers, חסר scoring cross עם float/short interest."
        )
    },
    "core/earnings_surprise_tracker.py": {
        "Role": "ניתוח הפתעות דוחות, איתור anomalies בתגובת שוק.",
        "Necessity": "עזר",
        "Missing_for_Pro": (
            "לא מחשב רצף/חזרתיות הפתעות, לא בודק השפעת surprise על מהלך מניה, "
            "לא משווה לציפיות אנליסטים."
        )
    },
    "core/growth_scanner.py": {
        "Role": "חישוב עקביות/צמיחה, זיהוי אנומליות.",
        "Necessity": "עזר",
        "Missing_for_Pro": (
            "לא מחשב variance/trend מורכב, אין חיתוך סקטור/מאקרו, חסר scoring."
        )
    },
    "core/valuation_anomaly_detector.py": {
        "Role": "איתור חריגות שווי, השוואת PE/Growth/Innovation.",
        "Necessity": "עזר",
        "Missing_for_Pro": (
            "לא מבצע חיתוך מגזר/סקטור, חסר scoring דינמי, לא משקלל גורמי חדשנות/צמיחה."
        )
    },
    # דוגמאות נוספות לסוכנים עתידיים או קבצי מערכת:
    "core/macro_trend_scanner.py": {
        "Role": "זיהוי מגמות מאקרו (GDP, FED, PMI, CPI, אינפלציה) והשפעתן על השוק.",
        "Necessity": "נדרש (חסר)",
        "Missing_for_Pro": (
            "לא קיים בפועל. דרוש שילוב API לנתוני מאקרו, ניתוח סטטיסטי, תצוגה גרפית, חיבור למנוע התראות."
        )
    },
    "core/social_media_hype_scanner.py": {
        "Role": "מדידת הייפ/סנטימנט מרשתות (Reddit, FinTwit, Stocktwits), איתור גלי hype.",
        "Necessity": "נדרש (חסר)",
        "Missing_for_Pro": (
            "לא קיים בפועל. דורש פיתוח ML לניתוח סנטימנט, אינטגרציה לאינדקסים, איתור שינוי חריג, scoring."
        )
    },
    "dashboard/main_dashboard.py": {
        "Role": "תצוגה גרפית, דוחות, התרעות, ניהול תסריטי אוטומציה, שילוב ML.",
        "Necessity": "מערכת",
        "Missing_for_Pro": (
            "חסר מנוע התראות, אין דוחות ML, לא כולל שילוב כל סוכני הליבה, אין backtesting/real-time."
        )
    },
    # ... אפשר להמשיך ולהוסיף כל קובץ/מודול/Agent לפי הצורך.
}

# בונה רשימה של כל הקבצים במערכת (כולל תתי-תיקיות)
def collect_all_files(root="."):
    all_files = []
    for dirpath, _, filenames in os.walk(root):
        for fname in filenames:
            # מוסיף רק קבצי py, ipynb, csv, json, md, txt, וגם legacy
            if fname.endswith(('.py', '.ipynb', '.csv', '.json', '.md', '.txt')):
                rel_path = os.path.join(dirpath, fname).replace("\\", "/")
                all_files.append(rel_path)
    return all_files

def get_manual_meta(path):
    if path in MANUAL_META:
        return MANUAL_META[path]
    # קובץ עזר/דוקו/דאטה/ניסוי/תשתית:
    if path.endswith(".md") or "readme" in path.lower():
        return {"Role": "תיעוד/דוקומנטציה", "Necessity": "עזר", "Missing_for_Pro": "אין צורך בפיתוח נוסף."}
    if path.endswith(".csv") or path.endswith(".json"):
        return {"Role": "דאטה/תצוגה", "Necessity": "עזר", "Missing_for_Pro": "קובץ נתונים; לא דורש גרסת על."}
    if path.endswith(".ipynb"):
        return {"Role": "ניסוי/מחקר", "Necessity": "עזר/Deprecated", "Missing_for_Pro": "קובץ ניסוי בלבד."}
    if "legacy" in path.lower():
        return {"Role": "Deprecated/ישן", "Necessity": "Deprecated", "Missing_for_Pro": "לא נדרש, אפשר למחוק."}
    return {"Role": "קובץ אחר", "Necessity": "לא מסווג", "Missing_for_Pro": "דרוש סיווג/סקירה ידנית."}

def build_report():
    files = collect_all_files(".")
    # הוספת קבצים נדרשים שלא קיימים בפועל (מתוך מחקר/תכנית עבודה)
    needed = [
        "core/macro_trend_scanner.py",
        "core/social_media_hype_scanner.py",
        "dashboard/main_dashboard.py",
        "core/news_catalyst_agent.py",
    ]
    for k in needed:
        if k not in files:
            files.append(k)
    records = []
    for path in sorted(files):
        fname = os.path.basename(path)
        meta = get_manual_meta(path)
        agent = fname.replace(".py", "")
        records.append({
            "Agent": agent,
            "Path": path,
            "Exists": os.path.exists(path),
            "Integrated": "TRUE" if meta["Necessity"] in ["ליבה", "עזר", "מערכת"] and os.path.exists(path) else "FALSE",
            "Advanced_Version": "FALSE",  # בודק לפי המילון בלבד; תוכל לסמן TRUE ידנית אחרי שדרוג
            "Role": meta["Role"],
            "Necessity": meta["Necessity"],
            "Missing_for_Pro": meta["Missing_for_Pro"],
        })
    df = pd.DataFrame(records)
    df.to_excel("agents_system_full_report.xlsx", index=False)
    print("דוח סוכנים מלא נוצר: agents_system_full_report.xlsx")

if __name__ == "__main__":
    build_report()


##### FILE: .\agent_status_report.py #####
import sys
import os
import json
import pandas as pd

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '')))
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), 'core')))
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), 'utils')))

from core.alpha_score_engine import AlphaScoreEngine
from utils import data_fetcher

SETTINGS_PATH = os.path.join(os.path.dirname(__file__), "settings.json") \
    if os.path.exists(os.path.join(os.path.dirname(__file__), "settings.json")) \
    else os.path.join(os.path.dirname(__file__), "config", "settings.json")

with open(SETTINGS_PATH, "r") as f:
    config = json.load(f)

engine = AlphaScoreEngine(config)

SYMBOLS = ["AAPL", "TSLA", "NVDA"]

def fetch_data(symbol):
    try:
        return data_fetcher.get_price_data(symbol, interval="1day", outputsize=100)
    except Exception as e:
        print(f"Error fetching price data for {symbol}: {e}")
        return None

def run_agent_report(symbol):
    price_df = fetch_data(symbol)
    if price_df is None:
        return {"symbol": symbol, "status": "NO DATA"}
    try:
        results = {}
        for agent_name, agent in engine.agents.items():
            try:
                # קריאה מותאמת פר סוכן
                if agent_name == "FloatPressureEvaluator":
                    result = agent.analyze(symbol, price_df)
                elif agent_name in [
                    "ShortSqueezePotentialAnalyzer",
                    "EarningsSurpriseTracker",
                    "GrowthConsistencyScanner",
                    "ValuationAnomalyDetector",
                    "SentimentScorer",
                    "GeopoliticalRiskMonitor"
                ]:
                    result = agent.analyze(symbol)
                else:
                    result = agent.analyze(price_df)
                results[agent_name] = (
                    "OK_TRUE" if result else "OK_FALSE"
                )
            except Exception as ex:
                print(f"[{symbol}][{agent_name}] ERROR: {type(ex).__name__} | {str(ex)}")
                results[agent_name] = f"ERROR: {type(ex).__name__} | {str(ex)}"
        return {"symbol": symbol, **results}
    except Exception as ex:
        print(f"[{symbol}] ENGINE ERROR: {type(ex).__name__} | {str(ex)}")
        return {"symbol": symbol, "status": f"ENGINE ERROR: {type(ex).__name__} | {str(ex)}"}

all_results = []
for symbol in SYMBOLS:
    row = run_agent_report(symbol)
    all_results.append(row)
    print(f"Finished {symbol}")

df = pd.DataFrame(all_results)
df.to_csv("outputs/agent_status_report.csv", index=False, encoding="utf-8-sig")
print("\n=== Agent Status Report ===")
print(df.to_string(index=False))
print("\n\nReport saved to outputs/agent_status_report.csv")


##### FILE: .\all_binary_files.txt #####


##### FILE: .\agents_system_full_report.xlsx #####
[BINARY FILE: .xlsx | BASE64 ENCODED BELOW]
UEsDBBQAAAAIAAAAPwD4SqchUQEAAJAEAAATAAAAW0NvbnRlbnRfVHlwZXNdLnhtbK2Uy07DMBBF90j8Q+QtStyyQAg17YLHEipRPsDYk8aqY1ueaWn/nkn6ECBoi9pNrGTu3HPHjjwYLRuXLSChDb4U/aInMvA6GOunpXibPOW3IkNS3igXPJRiBShGw8uLwWQVATPu9liKmijeSYm6hkZhESJ4rlQhNYr4NU1lVHqmpiCve70bqYMn8JRT6yGGgweo1NxR9rjkz+skCRyK7H4tbFmlUDE6qxVxXS68+UHJN4SCOzsN1jbiFQuE/JXQVv4GbPpeeGuSNZCNVaJn1bBKmqDHKUSUrC/2u/wSM1SV1cAe84ZbCmgDGTB5ZEtIZGGXeS9bhwT/h2/3qO0+krh0EmnlAE8eFWMCZbAGoMYVa9MDZOL/CdbP/sn8zuYA8COk2XsIs3MP265Fo6w/gt+JUXbL6VN/D7LzP3TktUpgXinxPXD2k//qvc0hu/tk+AlQSwMEFAAAAAgAAAA/AFB8TsHqAAAATAIAAAsAAABfcmVscy8ucmVsc62SzUoDMRCA74LvEObezbaCiDTbSxF6E6kPMCazP+wmE5JRt29vEBQrtfTgMZOZb74ZZr2Z/aTeKOWBg4FlVYOiYNkNoTPwvH9Y3IHKgsHhxIEMHCjDprm+Wj/RhFKKcj/ErAolZAO9SLzXOtuePOaKI4Xy03LyKOWZOh3RjtiRXtX1rU4/GdAcMdXOGUg7twS1P0S6hM1tO1jasn31FOREi18ZhYypIzEwT/qd0/jCPFYFCvq0y+pyl7/n1J4EHQpqy4kWMZXqJEPZ67eOY/tYwvkz45zQzX8uh2ah4MidV8IYv4z00Q00H1BLAwQUAAAACAAAAD8Ah+CFaeoAAAC6AgAAGgAAAHhsL19yZWxzL3dvcmtib29rLnhtbC5yZWxzrZLBasMwEETvhf6D2HstOy2llMi5hEKubfoBQlpbJrYktNuk/vuKhKYOhNCDT2JG7MyD3eXqe+jFHhN1wSuoihIEehNs51sFn9u3hxcQxNpb3QePCkYkWNX3d8t37DXnIXJdJJFTPClwzPFVSjIOB01FiOjzTxPSoDnL1MqozU63KBdl+SzTNAPqi0yxsQrSxlYgtmPE/2SHpukMroP5GtDzlQp5CGlHDpFzqE4tsoKzRfL4VEVOBXkdZjEnDOdZ/AM5ypN5k+FxTgbisc8bPUOc9K36p1nrnU5oPzjlc5tSTO1fGHlxcfUPUEsDBBQAAAAIAAAAPwDUvplOZQoAAB9SAAAYAAAAeGwvd29ya3NoZWV0cy9zaGVldDEueG1sjdxLcxpJFgXg/UTMfyDYj+Hm4yY4JHU0aac9i46YmNceS6VHtAQKoO2Zfz8gd3vynkoOuZN0qgp0BOKr5FJXP/3n5Xnyddjtn7ab66m8m08nw+Z2e/e0ebie/uuf5S+L6WR/WG/u1s/bzXA9/e+wn/508+c/XX3b7n7dPw7DYXI8wmZ/PX08HF7fz2b728fhZb1/t30dNsfkfrt7WR+O3+4eZvvX3bC+e9vp5Xnm5nOdvayfNtPvR3i/6znG9v7+6Xb4sL397WXYHL4fZDc8rw/H+79/fHrdT2+u7p6O2ekXmuyG++vpz/L+c4rT2c3V203/+2n4tq++nhzWX/4xPA+3h+Hu2MB0cvrNvmy3v57Cvx5/ND/tOhvtW97u1d92k7vhfv3b8+Hv22+fh6eHx8PxIP+/tQ/rw/rmarf9Ntm9HXz/uj6VJe8Xxzt6e/rhz6efvmXHPU93/+vN/Gr29XiTt79vsRpvIXaLPN7C2S0+jLfwdouP4y2C3aKMt4h2i0/jLdRu8Xm8RfqxxezY04+yXLMsV+24gJrqLMHt5u/hl1Z7H+odJUL7H2labAqtf7Jpgi5MqtLuwTd78NWuS+ihzhLcZvakB097oGnxtAdPe/A9PYRmD6HeFZ83dZjg0ZIDKSLQImhaAi0i0CJCTxGxWUSsd4XfZ1WHCR4uOZIiIi2CpiXSIiItIvYUoc0itN4VbnVVhwu4w1lJEUqLoGlRWoTSIrSniNQsItW7wj/7VR0u8NUkkSLMUSOkHxMtwqZwlz7ZFJ6un02qrl3EolnEot4VXtNWdbiAv01ekCIW9BFB07Kgj4gFfUQseh4Ry2YRS3NgKKIOF/C3yUtSxJIWQdOypEUsaRHLniJk3jbX3OyM3qrTBTxi8u9puwx74FEbPC4QYx8QYyHwS51r5IxCDS8TNlKni4iNCGtEeCM0LhCPGhHeiHQ10qamGJ4hNk26QG0K46Zwb/K4CBencHJKlzmljU4xUEN2mnSB7hQGT+Hy5HERbk/h+JQufUqbn1KLzY3O2+p0gQAVJlDhBOVxEY5Q4QqVLoZK26FS080hRE26QIkKo6hwi/K4CNeocI5Kl0elDVKpDedQpCZdIkmFmVQ4SnlchLNUuEulC6bSlqkYzI0aqdPlaKWD4VSoPz/yuEA8aiTxRlJXI22iSq06h1g36RKRKkypwpnK4yIcqsKlKl1UlbZVpeadQ7WbdIlaFcZV4V7lcREuVuFklS6zurZZXc07h3w36RLN6phZHTcrj4vjZnXcrK7LrK5tVmcWPFHxJl2iWR0zq+Nm5XFx3KyOm9V1mdWdWR6teedQ8SZdjlZI6RLphTXSC4ukF1ZJLyyTdpnVtc3qat650ZKxWUdFszpmVsfNyuPiuFkdN6vrMqtrm9UZs6LiTbpEszpmVsfNyuPiuFkdN6vrMqtrm9XVvPOoeJMu0ayOmdVxs/K4OG5Wx83quszq2mZ1Ne88Kt6kMke0OoZWx9HK4+I4Wh1Hq+tCq2uj1dW+84hWk8oc1eqYWh1XK4+L42p1XK2uS62urVZXA8+jWk0qc2SrY2x1nK08Lo6z1XG2ui62ujZbXS08j2w1qczRrY651XG38rg47lbH3eq63OrbbvU18Ty61aQyR7h6BlfP4crj4jlcPYer74Krb8PVm/fhEa4mlTnK1TO5ei5XHhfP5eq5XH2XXH1brr5Gnke5mlTmSFfP6Oo5XXlcPKer53T1fW/xn3mPv1aeR7qaVOaj9/npG/0X3um/8Fb/hff6L7zZ32VX37arr5nnR4MPdhoA8eoZXj3HK4+L53j1HK++C6++jVdfOy8gXk0qc9SrZ3r1XK88Lp7r1XO9+i69+rZefe28gHo1qeDQSPZMr57rlcfFc716rlffpVff1quvnRdQryYVHB/JnunVc73yuHiuV8/16rv06tt69bXzAurVpIKL1NkzvXquVx4Xz/XquV59l159W6++dl5AvZpUcKQke6ZXz/XK4+K5Xj3Xq+/Sa2jrNdTOC6hXkwoOl+TA9Bq4XnlcAtdr4HoNXXoNbb0GMyOKejWp4JhJDkyvgeuVxyVwvQau19Cl19DWa6idF1CvJhUcN8mB6TVwvfK4BK7XwPUauvQa2noNtfMC6tWkgvMmOTC9Bq5XHpfA9Rq4XkOXXsOZYdXaeQH1alLBgZMc6MDqhYnVCyOrF2ZWLwytduk1tPUaaufhHVuZVHDiJAem18D1yuMSuF4D12vo0mto6zXUzsMJy5VJBUdOcmB6DVyvPC6B6zVwvYYuvYa2XkPtPLzlVbDjBKjXwPQauF55XALXa+B6DV16DW29BuM81KtNcegkB6ZXu+9oxDdwvUKMQ74Q45Svjc+N+Ya2XkPtPLzllUkFZyxyYHq1+44r4XqFeFTJkley7KkktvUaa+dFBL1JBYcscmR6tfuOKolcrxBjJRBjJTY+W0lbr9F8fglBb1LBKYscmV4j1yuPS+R6jVyvsUuvsa3XWDsvIuhNKjhmkSPTa+R65XGJXK+R6zV26TW29Rpr5+GhVyYVnLPIkenV7jt+4nC9Qjx64nj+xPFdT5y2XqNxHv57tSkOWuTI9Gr3HVfC9QrxqJLAKwldlZz50JXRK57jmFRw0iJH+sGrC5+8uvDRqwufvbrw4asuvca2XqPRK57jmFRw1CJHptfI9crjErleI9dr7NJrbOs11s5TPMcxqeCsRY5Mr5Hrlcclcr1GrtfYpdfY1musnad4jhOtbVGvkek18rVXHpfI114jX3uNXWuvsa3XWDtP8RzHpIKzFjkyvUa+9srjEvnaa+Rrr7Fr7VXbetXaeYqvOCYVnLXIyvSqfO2Vx0X52qvytVftWnvVtl7VfLYeQW9SwVmLrEyvyvXK46Jcr8r1ql161bZetXaeIuhNKjhrkZXpVbleeVyU61W5XrVLr9rWq9bOUwS9SQVnLbIyvSpfe+VxUb72qnztVbvWXrWtV62dpwh6tbZFvSrTq/K1Vx4X5WuvytdetWvtVdt61dp5ino1qeCsRVamV+V65XFRrlfletUuveqZiwcYvY7+vRoF4qxFVnoBAQtMPMdRrleI8RwHYjzHsfG5cxxt61WNXhH0JhWctcjK9KpcrzwuyvWqXK/apVdt61Vr5yUEvUkFZy2yMr0q1yuPi3K9KterdulV23rV2nkJQW9SwVmLrEyvyvXK46Jcr8r1ql16TW29ptp5CUFvUsFZi5yYXhPXK49L4npNXK+pS6+prddkrvs0uiaJUSDOWuTE9Jq4XnlcEtdr4npNXXpNbb0mc9UqfMUxqeCsRU61XudYCdcrjwvEASux8RIrsXr1Zypp6zXRuVeTCs5a5MT0mrheeVwS12viek1dek1tvSYzOTB64hgF4qxFTkyvieuVxwVivBwcxKNHidVrOFNJW6/JXNQKT/tMKjhrkVNkTxyuVx4XiBUrsTydYyU2jlDJrLqo4Ov6YfhlvXt42uwnz8P9ca/5u6Nqdt+vQfj29WH7+vbV8aBftofD9uWP7x6H9d2wO313fFTeb7eHP745Xerwx6Udb/4HUEsDBBQAAAAIAAAAPwBSzOjvSwEAACcCAAAPAAAAeGwvd29ya2Jvb2sueG1sjZFNT8MwDIbvSPyHyHfWD20Vm9ZO4ktMQoDE2M6hcddoaVIlKR3/HqdTB9w42a9jP/LrLFfHRrFPtE4anUMyiYGhLo2Qep/D++bh6hqY81wLrozGHL7Qwaq4vFj2xh4+jDkwAmiXQ+19u4giV9bYcDcxLWp6qYxtuCdp95FrLXLhakTfqCiN4yxquNRwIizsfximqmSJd6bsGtT+BLGouKf1XS1bB8Wykgq3J0eMt+0zb2jvowKmuPP3QnoUOUxJmh7/FGzX3nRSBTGLZxAVZ5OvlgmseKf8hlYb6XSvdJqmWegMXVuJvfsZCpIdd1IL0+eQTum0X6NKZsD6Id9J4WsqZPH8XHtEua99DvMsiwM8+kUf7jdGpgdzbyFP6KNCXNP+lNuFpMSuRTIQxrGSq5LchDA0ptNZMgdWdUrdUu1FPxk+AMLQ6KT4BlBLAwQUAAAACAAAAD8AShyQ398GAAAiHAAAFAAAAHhsL3NoYXJlZFN0cmluZ3MueG1slVfbTttIGL5fad/BylUr0bittGi1C1Soh1WldoV62FtrYk8SC3vG6xkH6FPQli6gUkoRu9C8kF9nvxmH4HgOpEIhzsz3//Of5/Pao908Cya0FCln670H/fu9gLKYJykbrffevnl279deICRhCck4o+u9PSp6jzZ+/mlNCBlAlon13ljK4rcwFPGY5kT0eUEZdoa8zInEz3IUiqKkJBFjSmWehQ/v318Nc5KyXhDzisn13i8PV3tBxdK/K/q4WXmwutrbWBPpxprc2BxRJtdCubEWqoVmcYvIcXft6W4qpOiuPmeSjkoiadLd2UwmhMU0if5qAtDdf8Uz2l37k8ZUiFTudTdeplhmowh+R1sl724T5USEUMpKRCUteGm4pCHiFkyWRYOUkXIvGqYZFX25a8VIuivdiHhMSmxFMS9pJNT/0gURMWGwRVQZchmLiXFYsttoiIgtTSQrxmQGoGyUMiOghJFsT8gIGVLhs2uRpfcQbE94BgUZEmPHDHiWQT+FIlQZfWfYMUCJbvMKhlBJlT005iOWvjNDM6igSoyjgkhJSxaJgqsHI4LoGkRQpvG23aTrEDeZjpqGsSnKCEorVi5WOfJVlSMaJbAyltwAU1Iy+CkUrChTQSNZknjb1IpeTbPrswVliQkZotBYnJJM1eTAE9xhxomM0OQCpyLRE5JVxGLciBRzwyNUVAqHjUSMKC84zkpjHAwPtqOcs9SmjWcJZVFcciGc8RiVfEeOdRkz08NxOhqjC9gkjSUGQMRLDDGBiFk05SROYEoO/6vceV6eJkhhfgO0BiznE13smLzYv4ncgJtQFadGS4S4ponNNkZ30M1ENq1kPbIgJUEToI6s2xiAkWDpcGgGCcWBTOnxZR0VYqxLqGmrSPezpWsE15WU0yQl0XivoK6ciKrQNfkOFw4Kr8TYQAJd8VbthaYeEBmPo7KyKUQ6ExTlLo0rnWREG8EwcRN0g7oKYaU1RE1VKw0uY1pDyDOuZn0sKVOXDiJi6fnJDlrFLq12VFQSR2kRVsGDpiVRLMQ2tZuoWQd6xke2KyOnauroGwUDDy4uccHZ1GPKqr6HKmpeyHrwLjUkNFLdt5mqER5vWwGdme7HiLik1FY+CmW/u/QWpiQbVwPr3i1N11w07s5rvLT1gxW5WFhdiKoFRB19Yp30yocIDZIZBGqY7kYxNbnIMC/sAnKHZhNq38MULfmsfh0DQFFDVK4YDzgpjRrph7ZKKww+NsOJZYBLkKoG5adV/dBCrKwnLsuugISOsEOy7Co10KBbHqyFeHnQixTMD+ySMTfaoGUeqJOgeWTsVM0tYJA2D3TZXLfBXa7nkfCxPreYk/95REwm6AY7OaFHxMEO3RLWK8ADdzFGj4iNO3rgCyzSjfPxSbeUnVl68FaO6cG72aZHyMY73XALA3WDO9eiG9i6G92gLj/1IK1M1YN3cVaPiJe9uuUsPNYDdjBat0SX23qQBsv1YK1814s3mK8HPefAt2BabNiKVMznB65cDV+KRs+wHjbdD8GnQwen7ocGq7baj0uvqKSwEh/rmdcCy/u8QMutRri5uRveJuhOlAhtXH1p+DVtv03AQ4daqBkRvg22zABrwW8bYy2odX7cJrTYV3a0r0Y1Uw/bLwhWHQ1s4V3Bi2teG3yQ6zcID6b9MmGBXV+g3ZcKF3S5e+qHp//8dSVcfHuxQJ9tvnj9tLv45tVbY62+rD/V7+t/g3q/PqyvjO2PWD+qD8J6Wv8H5If6wID8Ux/XB9g7DupTAE7xOFWP+9B9VX8K7vzxZGslePb0yUqw9fL5SvB4C/+we1yf1Rf1CfRC/m4AsYP6O1bOcdbXAF8ngV75VF/2jUNPYdkxPlOFOcbfRVh/g8IjPJ6qb2XBFaSn2pw7r2iSpBJmpOzNjnp4reaFxKO4O7NGIa8CeHACV1QqzFPnQVCwK9gKKUh/xOKhOmdFWTPFzvns19ksNnBlCvuu8PNIBWofa0f4nDbeA/kd3ycqF8HLF+bBJ/W+cugbADjf2D5HEszcncEwhCC4A+Nw9l1LEM8B+FxPLWlH5iAKuePmTBXeS/y4Us6ryCvXpqal83o60wFVqC+/B40DKk7KIB28byp3SLLD2Uud1S8BlF1ATAGDG7NuorW59Vxpn5/WqrxZ/NXGofLkSFeH+j5eCVy5PMT3+6YSTnQl4ezrrKqsWVz22Ttz+GJux8sXjbktu1pVO2+MI22ULg4dPL34EaeohHxZrNjvelM34KEusQ8rgaJKuBhNY3UpBFbPZlq/tgoa5q7MkvdZlbEq5JvYY+0k0EX5uQn9geodROBgrmqA90J1fcAWff/fUwSgZVUohNz4H1BLAwQUAAAACAAAAD8AcRgVrf0BAAA+BQAADQAAAHhsL3N0eWxlcy54bWy9VN+LnDAQfi/0fwh577kKPdqiHr2DhUJbCreFvkaNGsgPScZF76/vJHHVhTsW+tAXMzP55puZLzH5w6QkOXPrhNEFTe8OlHBdm0borqC/T8cPnyhxwHTDpNG8oDN39KF8/y53MEv+3HMOBCm0K2gPMHxJElf3XDF3Zwaucac1VjFA13aJGyxnjfNJSibZ4XCfKCY0LfPWaHCkNqOGgmZLoMzdCzkziX2lNCnz2khjCSA9NhIimikeEU9MisoKH2yZEnKO4cwHQkcLTgltrA8msUL8Vsn/qBUWh0lCyuthMVDmAwPgVh/RIYt9mgcsr1H5SBNwN9CdZXOafdwlhAXrVsY2eNL7yjFU5pK3gAlWdL1fwQyJ3wQwCo1GsM5oJj3lJWOfScJlKCj04TCjdmwEs0iXeNDCfhMbUKGFm1DEXLq8iY2w12dZDJSo5lI+e6Y/7apTinxTS/Sojgq+NQXFf8Sf5MVEcRcz0kTH8+/ZIveONvsnWjK1K/9b2ekb2emWTdgwyPlo4nzRewzAzf8qRacVv0jALi7pjRUvmOrveI0Bbql/QkDUPoKHEoaf2kWBdfggxZWsa5T4v6ugP/1jIXdtVqOQIPQrkiJnM21qhl1gFb5JV1WQo+EtGyWc1s2CbvYP3ohRfV5Rv8TZwILa7O/+Tqb3oYPt4Sv/AlBLAwQUAAAACAAAAD8A6aYluLIFAABTGwAAEwAAAHhsL3RoZW1lL3RoZW1lMS54bWztWU2P20QYviPxH0a+t44TO82umq022aSFdtvVblrU48SZ2NOMPdbMZLe5ofaIhIQoiAsSNw4IqNRKXMqvWSiCIvUv8PojyXgz3mbbRRS1OSSe8fN+f/gd5/KV+xFDh0RIyuO25VysWYjEPh/ROGhbtwf9Cy0LSYXjEWY8Jm1rRqR1ZevDDy7jTRWSiCCgj+UmbluhUsmmbUsftrG8yBMSw70xFxFWsBSBPRL4CPhGzK7Xak07wjS2UIwjYHtrPKY+QYOUpbU1Z95j8BUrmW74TBz4mUSdIsOOJk76I2eyywQ6xKxtgZwRPxqQ+8pCDEsFN9pWLftY9tZle0HEVAWtRtfPPgVdQTCa1DM6EQwXhE7f3bi0s+Bfz/mv4nq9XrfnLPhlAOz7YKmzgnX7Lacz56mB8stV3t2aV3PLeI1/YwW/0el0vI0SvrHEuyv4Vq3pbtdLeHeJ91b172x3u80S3lvimyv4/qWNplvGZ6CQ0Xiygk7juYjMAjLm7JoR3gJ4a54AS5StZVdOH6uqXIvwPS76AMiCixWNkZolZIx9wHVxNBQUpwLwJsHanXzLlytbqSwkfUET1bY+TjBUxBLy8tmPL589QS+fPT5+8PT4wS/HDx8eP/jZQHgNx4FO+OL7L/7+9lP015PvXjz6yoyXOv73nz777dcvzUClA59//fiPp4+ff/P5nz88MsC3BR7q8AGNiEQ3yRHa5xHYZhBAhuJsFIMQ0xIFDgFpAPZUWALenGFmwnVI2Xl3BDQAE/Dq9F5J14NQTBU1AK+HUQm4yznrcGE053oqSzdnGgdm4WKq4/YxPjTJ7p4IbW+aQCZTE8tuSEpq7jGINg5ITBRK7/EJIQayu5SW/LpLfcElHyt0l6IOpkaXDOhQmYmu0QjiMjMpCKEu+Wb3DupwZmK/Qw7LSCgIzEwsCSu58SqeKhwZNcYR05E3sApNSh7MhF9yuFQQ6YAwjnojIqWJ5paYldS9jqETGcO+y2ZRGSkUnZiQNzDnOnKHT7ohjhKjzjQOdexHcgIpitEeV0YleLlC0jXEAceV4b5DiTpbWd+mQWhOkPTOVBRdu9R/Ixqf1owZhW78vhnP4dvwaDKVxMkWXIX7HzbeHTyN9wjk+vu++77vvot9t6qW1+22ywZr63Nxxi+qHJLHlLEDNWPkhsxaswSlR33YzBYZ0WImT0K4LMSVcIHA2TUSXH1CVXgQ4gTEOJmEQBasA4kSLuEkYFXyzo6TFIzP9rz5GRDQWO3yUb7d0M+GCzbZKpC6oEbKYF1hjUtvJszJgWtKczyzNO9UabbmTagGhNOTv9Os56IhYzAjo9TvOYN5WM49RDLEI1LEyDEa4jTWdFvr1V7TpG003kzaOkHSxbkV4rxziFJtJUr2ajmyuLxCR6CVV/cs5OOkbY1hkoLLKAF+Mm1AmAVx2/JVYcori/mkwea0dGqVBpdEJEKqHSzDnCq7NX91Ei/1r3tu6ofzMcDQjdbTotFy/kMt7JOhJeMx8VXFznJZ3ONTRcRBODpCQzYV+xj0dvPsGlEJz4z6fCGgQt0i8cqVX1TByVc0RXVgloS46EktLfY5PLte6JCtNPXsCt1f05TGOZrivbumpJkLY2tjlB2oYAwQGKU52ra4UCGHLpSE1O8LGBwyWaAXgrJIVUIsfeGc6koOl30r55E3uSBU+zRAgkKnU6EgZE8Vdr6CmVPXn69zRkWfWagrk/x3SA4JG6TV20ztt1A47yaFIzLcyaDZpuoaBv23ePJxKyaf08eDpSD3LLOIqzV97VGw8WYqnPFRWzdbXPfWftQmcPhA6Rc0bip8tpxvB3wfoo8WEyWCRLzQKspvsTkEnVuacSmrf3eMWoagVRHv8xw+NWc3Kpx9urjXd7Zn8LV3uqvt1RK1tYNMtlr544kP74HsHTgoTZmS+duk+3DU7M7/MgA+9pJ06x9QSwMEFAAAAAgAAAA/AM8lIqMnAQAAUQIAABEAAABkb2NQcm9wcy9jb3JlLnhtbJ2SX0vDMBTF3wW/Q8l7m6bFKaHtQGVPDgQnim8huduCzR+SaLdvb9pu3QZ78vHmnPu7515SzXeqTX7BeWl0jUiWowQ0N0LqTY3eV4v0ASU+MC1YazTUaA8ezZvbm4pbyo2DV2csuCDBJ5GkPeW2RtsQLMXY8y0o5rPo0FFcG6dYiKXbYMv4N9sALvJ8hhUEJlhguAemdiKiA1LwCWl/XDsABMfQggIdPCYZwSdvAKf81YZBOXMqGfYWrlqP4uTeeTkZu67LunKwxvwEfy5f3oZVU6n7W3FATSU45Q5YMK6p8HkRD9cyH5bxxmsJ4nEf9Stvh0XGPhBJDEDHuEflo3x6Xi1QU+TFXZrfp6RckZKSGSX5Vz/yov8EVIch/yYeAWPuy0/Q/AFQSwMEFAAAAAgAAAA/ACc4i8R7AQAAEQMAABAAAABkb2NQcm9wcy9hcHAueG1snZJBa+MwEIXvhf0PRvdEdliWEmSVkuzSw5YGkrZnVR7HorIkNFOT9NdXdojrtHtan97MPJ4+jyRuDq3NOohovCtZMc9ZBk77yrh9yR53f2bXLENSrlLWOyjZEZDdyB9XYhN9gEgGMEsRDkvWEIUl56gbaBXO09ilSe1jqyiVcc99XRsNa6/fWnDEF3n+i8OBwFVQzcIYyE6Jy47+N7TyuufDp90xpDwpbkOwRitKfynvjY4efU3Z74MGK/h0KFLQFvRbNHSUueDTUmy1srBKwbJWFkHwz4a4A9UvbaNMRCk6WnagyccMzXta24JlLwqhxylZp6JRjtjJdioGbQNSlM8+vmIDQCj42Bzk1DvV5qcsBkMSl0Y+giR9ibgzZAEf6o2K9A/iYko8MLAJ47bnK77xnU/6kr3ybVAuLZCP6q9xr/gYdn6tCM7rvGyKbaMiVOkGxnWPDXGXuKLt/atGuT1UZ8/3QX/5T6cXLovFPE/fcOfnnuCfb1l+AFBLAQIUABQAAAAIAAAAPwD4SqchUQEAAJAEAAATAAAAAAAAAAAAAAC2gQAAAABbQ29udGVudF9UeXBlc10ueG1sUEsBAhQAFAAAAAgAAAA/AFB8TsHqAAAATAIAAAsAAAAAAAAAAAAAALaBggEAAF9yZWxzLy5yZWxzUEsBAhQAFAAAAAgAAAA/AIfghWnqAAAAugIAABoAAAAAAAAAAAAAALaBlQIAAHhsL19yZWxzL3dvcmtib29rLnhtbC5yZWxzUEsBAhQAFAAAAAgAAAA/ANS+mU5lCgAAH1IAABgAAAAAAAAAAAAAALaBtwMAAHhsL3dvcmtzaGVldHMvc2hlZXQxLnhtbFBLAQIUABQAAAAIAAAAPwBSzOjvSwEAACcCAAAPAAAAAAAAAAAAAAC2gVIOAAB4bC93b3JrYm9vay54bWxQSwECFAAUAAAACAAAAD8AShyQ398GAAAiHAAAFAAAAAAAAAAAAAAAtoHKDwAAeGwvc2hhcmVkU3RyaW5ncy54bWxQSwECFAAUAAAACAAAAD8AcRgVrf0BAAA+BQAADQAAAAAAAAAAAAAAtoHbFgAAeGwvc3R5bGVzLnhtbFBLAQIUABQAAAAIAAAAPwDppiW4sgUAAFMbAAATAAAAAAAAAAAAAAC2gQMZAAB4bC90aGVtZS90aGVtZTEueG1sUEsBAhQAFAAAAAgAAAA/AM8lIqMnAQAAUQIAABEAAAAAAAAAAAAAALaB5h4AAGRvY1Byb3BzL2NvcmUueG1sUEsBAhQAFAAAAAgAAAA/ACc4i8R7AQAAEQMAABAAAAAAAAAAAAAAALaBPCAAAGRvY1Byb3BzL2FwcC54bWxQSwUGAAAAAAoACgCAAgAA5SEAAAAA

##### FILE: .\charles_core_scorer.py #####
# charles_core_scorer.py

def score_stock(symbol, rsi_flag, float_flag, vol_flag, para_flag):
    explanation = []
    score = 0
    active_signals = 0

    if rsi_flag is not None:
        active_signals += 1
        if rsi_flag:
            score += 1
            explanation.append("✅ RSI מצביע על דחיסה – פוטנציאל תזוזה חזקה בקרוב.")
        else:
            explanation.append("⚠️ RSI לא מצביע על דחיסה.")

    if float_flag is not None:
        active_signals += 1
        if float_flag:
            score += 1
            explanation.append("🔥 Float Pressure גבוה – ייתכן לחץ שורט חיובי.")
        else:
            explanation.append("📉 אין לחץ שורט משמעותי.")

    if para_flag is not None:
        active_signals += 1
        if para_flag:
            score += 1
            explanation.append("📈 תנועה פראבולית חזקה לאחרונה.")
        else:
            explanation.append("🔎 לא זוהתה תנועה פראבולית משמעותית.")

    if vol_flag is not None:
        active_signals += 1
        if vol_flag:
            score += 1
            explanation.append("💤 תנודת נפח נמוכה – מניה 'מבשילה'.")
        else:
            explanation.append("📊 נפח תנודתי – לא מראה דחיסה.")

    # Confidence לפי כמות סוכנים פעילים
    confidence = round((active_signals / 4) * 100)

    # המלצה כללית
    if score == 4:
        recommendation = "🚀 Candidate for Breakout (High Conviction)"
    elif score == 3:
        recommendation = "🔥 Strong Speculative Setup"
    elif score == 2:
        recommendation = "👀 Monitor – partial alignment"
    elif score == 1:
        recommendation = "⚠️ Weak Signal – not tradable alone"
    else:
        recommendation = "❌ No signal – ignore"

    return {
        "symbol": symbol,
        "alpha_score": score,
        "confidence": confidence,
        "recommendation": recommendation,
        "explanation": explanation
    }


##### FILE: .\charles_scan_results.csv #####
ticker,RSI Signal,Volume Tension,Float Pressure,Parabolic Signal,BreakoutRetest,Alpha Score
AAPL,RSI Error: get_price_df() got an unexpected keyword argument 'period',"            close
date             
1980-12-12   True
1980-12-15   True
1980-12-16   True
1980-12-17   True
1980-12-18   True
...           ...
2025-06-27  False
2025-06-30  False
2025-07-01  False
2025-07-02  False
2025-07-03  False

[11231 rows x 1 columns]",Unavailable,Parabolic Error: 'volume',Error: 'open',"🟡 Alpha Score: 2 (Float❌, Parabolic🔥)"
MSFT,RSI Error: get_price_df() got an unexpected keyword argument 'period',"            close
date             
1986-03-13   True
1986-03-14   True
1986-03-17   True
1986-03-18   True
1986-03-19   True
...           ...
2025-06-27  False
2025-06-30  False
2025-07-01  False
2025-07-02  False
2025-07-03  False

[9904 rows x 1 columns]",Unavailable,Parabolic Error: 'volume',Error: 'open',"🟡 Alpha Score: 2 (Float❌, Parabolic🔥)"


##### FILE: .\merge_files_split.py #####
import os
import base64

exclude_dirs = {'__pycache__', '.git', '.vscode', 'Charles_FocusedSpec_Backup'}
binary_exts = {'.png', '.jpg', '.jpeg', '.gif', '.bmp', '.ico', '.xls', '.xlsx', '.pdf', '.zip'}

def is_binary(filename):
    return os.path.splitext(filename)[1].lower() in binary_exts

text_output = "all_text_files.txt"
binary_output = "all_binary_files.txt"

with open(text_output, "w", encoding="utf-8") as text_out, \
     open(binary_output, "w", encoding="utf-8") as binary_out:

    for root, dirs, files in os.walk("."):
        dirs[:] = [d for d in dirs if d not in exclude_dirs]
        for filename in files:
            filepath = os.path.join(root, filename)
            ext = os.path.splitext(filename)[1].lower()
            # בודק האם קובץ בינארי (תמונה/אקסל וכו')
            try:
                if is_binary(filename):
                    with open(filepath, "rb") as binfile:
                        encoded = base64.b64encode(binfile.read()).decode('ascii')
                    binary_out.write(f"\n\n##### FILE: {filepath} #####\n")
                    binary_out.write(f"[BINARY FILE: {ext} | BASE64 ENCODED BELOW]\n")
                    binary_out.write(encoded)
                else:
                    with open(filepath, "r", encoding="utf-8") as infile:
                        text_out.write(f"\n\n##### FILE: {filepath} #####\n")
                        text_out.write(infile.read())
            except Exception as e:
                # קבצים שלא קריאים כאחד מהסוגים
                err_text = f"[UNREADABLE FILE: {e}]\n"
                if is_binary(filename):
                    binary_out.write(f"\n\n##### FILE: {filepath} #####\n")
                    binary_out.write(err_text)
                else:
                    text_out.write(f"\n\n##### FILE: {filepath} #####\n")
                    text_out.write(err_text)


##### FILE: .\realtime_feed.py #####
import websocket
import json
import pandas as pd
import time
import threading

from utils import data_fetcher
from core.alpha_score_engine import AlphaScoreEngine

# מפתחות API (Finnhub)
FINNHUB_KEY = "d1in1ahr01qhbuvr1dggd1in1ahr01qhbuvr1dh0"

# רשימת סימולים
SYMBOLS = ["QBTS"]

# פרמטר: כל כמה שניות לבצע הערכה מחודשת (מניעת יותר מדי קריאות API)
EVAL_INTERVAL_SEC = 120

# זיכרון מתי כל סימול נבדק לאחרונה
last_evaluated = {}

# טוען קונפיגורציה
with open("config/settings.json", "r") as f:
    config = json.load(f)

engine = AlphaScoreEngine(config)

def evaluate_symbol(symbol):
    try:
        price_df = data_fetcher.get_price_data(symbol, interval="1day", outputsize=100)
        result = engine.evaluate(symbol, price_df)
        print(f"[{symbol}] AlphaScore: {result['score']} | {result['recommendation']}")
        # כאן אפשר להוסיף: שליחת התראה/מייל/וואטסאפ וכו׳ אם התוצאה היא קניה חזקה!
        if result['recommendation'].startswith("HIGH"):
            print(f"🚨🚨 SIGNAL: {symbol} = STRONG BUY 🚨🚨")
        return result
    except Exception as e:
        print(f"Error evaluating {symbol}: {e}")

def on_message(ws, message):
    data = json.loads(message)
    if data.get("type") == "trade":
        for trade in data["data"]:
            symbol = trade['s']
            print(f"Live trade: {symbol} | Price: {trade['p']} | Volume: {trade['v']}")
            # נבדוק אם עבר מספיק זמן מאז ההערכה האחרונה
            now = time.time()
            if symbol not in last_evaluated or now - last_evaluated[symbol] > EVAL_INTERVAL_SEC:
                threading.Thread(target=evaluate_symbol, args=(symbol,)).start()
                last_evaluated[symbol] = now

def on_error(ws, error):
    print(f"WebSocket error: {error}")

def on_close(ws, close_status_code, close_msg):
    print("WebSocket connection closed")

def on_open(ws):
    # נרשם לקבלת עדכונים
    for sym in SYMBOLS:
        ws.send(json.dumps({"type": "subscribe", "symbol": sym}))
    print(f"Subscribed to real-time data for: {SYMBOLS}")

if __name__ == "__main__":
    socket_url = f"wss://ws.finnhub.io?token={FINNHUB_KEY}"
    ws_app = websocket.WebSocketApp(socket_url,
                                    on_open=on_open,
                                    on_message=on_message,
                                    on_error=on_error,
                                    on_close=on_close)
    print("Connecting to Finnhub WebSocket...")
    ws_app.run_forever()


##### FILE: .\test_gap_detector_ultimate.py #####
from utils import data_fetcher
from core.gap_detector_ultimate import GapDetectorUltimate  # או השם של הקובץ/קלאס שלך

symbol = "TSLA"  # תוכל לבדוק גם AAPL, MSFT, וכו'
price_df = data_fetcher.get_price_history(symbol, period="6mo", interval="1d")

if price_df is None or price_df.empty:
    print("שגיאה: לא התקבלו נתוני מחיר")
else:
    agent = GapDetectorUltimate()  # ודא שאתה משתמש בשם הקלאס/קובץ הנכון
    score = agent.analyze(symbol, price_df)
    print(f"Gap Ultimate Score for {symbol}: {score}")


##### FILE: .\test_single_stock.py #####
import pandas as pd
from utils import data_fetcher
from core.alpha_score_engine import AlphaScoreEngine

if __name__ == "__main__":
    symbol = input("הזן סימול מניה לבדיקה (למשל MSFT): ").strip().upper() or "MSFT"
    price_df = data_fetcher.get_price_history(symbol)
    engine = AlphaScoreEngine()
    result = engine.evaluate(symbol, price_df)
    print(f"\n=== ניתוח מניית {symbol} ===")
    print("Score כולל:", result["score"])
    print("המלצה:", result["recommendation"])
    print("\nפירוט ציונים (1-100) של כל הסוכנים:")
    for agent, score in result["signals"].items():
        print(f"{agent:22}: {score}")


##### FILE: .\tickers.csv #####
ticker
AAPL
MSFT


##### FILE: .\config\settings.Json #####
{
  "RSICompressionSniffer": { "lookback": 14, "tolerance": 5 },
  "BreakoutRetestRecognizer": { "window": 20, "tolerance": 2 },
  "FloatPressureEvaluator": { "sources": ["FMP", "manual"] },
  "SupportZoneStrengthDetector": { "window": 60, "tolerance_pct": 3 },
  "MovingAveragePressureBot": {
    "ma_periods": [50, 100, 200],
    "pressure_threshold": 0.02
  },
  "BullishPatternSpotter": {
    "min_days": 5,
    "pattern_types": ["cup_and_handle", "flag", "w_pattern"]
  },
  "ShortSqueezePotentialAnalyzer": {
    "short_ratio_threshold": 0.15,
    "days_to_cover_threshold": 3
  },
  "EarningsSurpriseTracker": {
    "surprise_threshold": 5
  },
  "GrowthConsistencyScanner": {
    "min_years": 3,
    "min_revenue_growth": 10,
    "min_profit_growth": 8
  },
  "ValuationAnomalyDetector": {
    "pe_max": 15,
    "growth_min": 10
  },
  "SocialMediaHypeScanner": {
    "hype_threshold": 5
  },
  "NewsCatalystAgent": {
    "keywords": ["acquisition", "FDA", "merger", "approval"]
  },
  "GeopoliticalRiskMonitor": {
    "sensitive_regions": ["Middle East", "China", "Russia"]
  },
  "SentimentScorer": {
    "min_sentiment_score": 0.3
  }
}


##### FILE: .\core\adx_score_agent.py #####
import pandas as pd
import numpy as np

class ADXScoreAgent:
    def __init__(self, config=None):
        self.lookback = config.get("lookback", 14) if config else 14

    def analyze(self, price_df):
        if price_df is None or len(price_df) < self.lookback + 1:
            return 1
        high = price_df["high"]
        low = price_df["low"]
        close = price_df["close"]

        plus_dm = high.diff()
        minus_dm = -low.diff()
        plus_dm[plus_dm < 0] = 0
        minus_dm[minus_dm < 0] = 0

        tr1 = high - low
        tr2 = (high - close.shift()).abs()
        tr3 = (low - close.shift()).abs()
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        atr = tr.rolling(self.lookback).mean()

        plus_di = 100 * (plus_dm.rolling(self.lookback).mean() / atr)
        minus_di = 100 * (minus_dm.rolling(self.lookback).mean() / atr)
        dx = (abs(plus_di - minus_di) / (plus_di + minus_di)) * 100
        adx = dx.rolling(self.lookback).mean()

        adx_last = adx.iloc[-1] if not adx.empty else 0
        score = int(max(1, min(100, adx_last)))
        return score


##### FILE: .\core\alpha_score_engine.py #####
import traceback

class DummyAgent:
    """Agent Placeholder - לסוכנים שעוד לא הוקמו"""
    def __init__(self, config=None):
        pass

    def analyze(self, symbol, price_df):
        return {
            "score": 1,
            "explanation": "Agent זה טרם מומש, יש להשלים את הקוד בעתיד.",
            "details": {},
        }

class AlphaScoreEngine:
    """
    AlphaScoreEngine גרסה סופית - כולל את כל הסוכנים המוגדרים בתוכנית, במחקר, ובקוד
    אין צורך להוסיף/להסיר קוד, רק לממש את הקובץ הספציפי של הסוכן.
    """

    AGENT_WEIGHTS = {
        "RSICompressionSniffer": 2,
        "VolumeTensionMeter": 2,
        "ParabolicAgent": 1,
        "BreakoutRetestRecognizer": 1,
        "SupportZoneStrengthDetector": 1,
        "MovingAveragePressureBot": 1,
        "BullishPatternSpotter": 2,
        "FloatPressureEvaluator": 1,
        "ShortSqueezePotentialAnalyzer": 2,
        "EarningsSurpriseTracker": 2,
        "GrowthConsistencyScanner": 1,
        "ValuationAnomalyDetector": 1,
        "SentimentScorer": 2,
        "GeopoliticalRiskMonitor": 1,
        "GapDetectorUltimate": 2,
        "AnalystRatingAgent": 2,
        "ADXScoreAgent": 1,
        "NewsCatalystAgent": 3,
        "SocialMediaHypeScanner": 2,
        "MacroTrendScanner": 2,
        "PatternRecognitionAgent": 3,
        "AnomalyDetectionAgent": 2,
        "LiquidityTrapAgent": 2,
        "BollingerSqueezeAgent": 2,
        "VolumeSpikeAgent": 2,
        "GoldenCrossAgent": 2,
        "VCPSuperPatternAgent": 3,
        "ReversalPatternAgent": 2,
        "FundamentalAnomalyAgent": 2,
        "MarketRegimeAgent": 1,
        "BigMoneyInflowAgent": 2,
        "RiskEventMonitorAgent": 2,
        # תוכל להוסיף כאן סוכנים עסקיים/מחקריים נוספים
    }

    def __init__(self, config=None):
        cfg = config or {}

        def try_import(path, classname):
            try:
                module = __import__(path, fromlist=[classname])
                return getattr(module, classname)
            except Exception:
                return DummyAgent  # תמיד יחזור דמי עד שיהיה קובץ

        self.agents = {
            "RSICompressionSniffer": try_import('core.rsi_sniffer', 'RSICompressionSniffer')(cfg.get("RSICompressionSniffer")),
            "VolumeTensionMeter": try_import('core.volume_tension_meter', 'VolumeTensionMeter')(cfg.get("VolumeTensionMeter")),
            "ParabolicAgent": try_import('core.parabolic_agent', 'ParabolicAgent')(cfg.get("ParabolicAgent")),
            "BreakoutRetestRecognizer": try_import('core.breakout_retest_recognizer', 'BreakoutRetestRecognizer')(cfg.get("BreakoutRetestRecognizer")),
            "SupportZoneStrengthDetector": try_import('core.support_zone_strength_detector', 'SupportZoneStrengthDetector')(cfg.get("SupportZoneStrengthDetector")),
            "MovingAveragePressureBot": try_import('core.moving_average_pressure_bot', 'MovingAveragePressureBot')(cfg.get("MovingAveragePressureBot")),
            "BullishPatternSpotter": try_import('core.bullish_pattern_spotter', 'BullishPatternSpotter')(cfg.get("BullishPatternSpotter")),
            "FloatPressureEvaluator": try_import('core.float_pressure_evaluator', 'FloatPressureEvaluator')(cfg.get("FloatPressureEvaluator")),
            "ShortSqueezePotentialAnalyzer": try_import('core.short_squeeze_analyzer', 'ShortSqueezePotentialAnalyzer')(cfg.get("ShortSqueezePotentialAnalyzer")),
            "EarningsSurpriseTracker": try_import('core.earnings_surprise_tracker', 'EarningsSurpriseTracker')(cfg.get("EarningsSurpriseTracker")),
            "GrowthConsistencyScanner": try_import('core.growth_scanner', 'GrowthConsistencyScanner')(cfg.get("GrowthConsistencyScanner")),
            "ValuationAnomalyDetector": try_import('core.valuation_detector', 'ValuationAnomalyDetector')(cfg.get("ValuationAnomalyDetector")),
            "SentimentScorer": try_import('core.sentiment_scorer', 'SentimentScorer')(cfg.get("SentimentScorer")),
            "GeopoliticalRiskMonitor": try_import('core.geopolitical_risk_monitor', 'GeopoliticalRiskMonitor')(cfg.get("GeopoliticalRiskMonitor")),
            "GapDetectorUltimate": try_import('core.gap_detector_ultimate', 'GapDetectorUltimate')(cfg.get("GapDetectorUltimate")),
            "AnalystRatingAgent": try_import('core.analyst_rating_agent', 'AnalystRatingAgent')(cfg.get("AnalystRatingAgent")),
            "ADXScoreAgent": try_import('core.adx_score_agent', 'ADXScoreAgent')(cfg.get("ADXScoreAgent")),
            "NewsCatalystAgent": try_import('core.news_catalyst_agent', 'NewsCatalystAgent')(cfg.get("NewsCatalystAgent")),
            "SocialMediaHypeScanner": try_import('core.social_media_hype_scanner', 'SocialMediaHypeScanner')(cfg.get("SocialMediaHypeScanner")),
            "MacroTrendScanner": try_import('core.macro_trend_scanner', 'MacroTrendScanner')(cfg.get("MacroTrendScanner")),
            "PatternRecognitionAgent": try_import('core.pattern_recognition_agent', 'PatternRecognitionAgent')(cfg.get("PatternRecognitionAgent")),
            "AnomalyDetectionAgent": try_import('core.anomaly_detection_agent', 'AnomalyDetectionAgent')(cfg.get("AnomalyDetectionAgent")),
            "LiquidityTrapAgent": try_import('core.liquidity_trap_agent', 'LiquidityTrapAgent')(cfg.get("LiquidityTrapAgent")),
            "BollingerSqueezeAgent": try_import('core.bollinger_squeeze_agent', 'BollingerSqueezeAgent')(cfg.get("BollingerSqueezeAgent")),
            "VolumeSpikeAgent": try_import('core.volume_spike_agent', 'VolumeSpikeAgent')(cfg.get("VolumeSpikeAgent")),
            "GoldenCrossAgent": try_import('core.golden_cross_agent', 'GoldenCrossAgent')(cfg.get("GoldenCrossAgent")),
            "VCPSuperPatternAgent": try_import('core.vcp_super_pattern_agent', 'VCPSuperPatternAgent')(cfg.get("VCPSuperPatternAgent")),
            "ReversalPatternAgent": try_import('core.reversal_pattern_agent', 'ReversalPatternAgent')(cfg.get("ReversalPatternAgent")),
            "FundamentalAnomalyAgent": try_import('core.fundamental_anomaly_agent', 'FundamentalAnomalyAgent')(cfg.get("FundamentalAnomalyAgent")),
            "MarketRegimeAgent": try_import('core.market_regime_agent', 'MarketRegimeAgent')(cfg.get("MarketRegimeAgent")),
            "BigMoneyInflowAgent": try_import('core.big_money_inflow_agent', 'BigMoneyInflowAgent')(cfg.get("BigMoneyInflowAgent")),
            "RiskEventMonitorAgent": try_import('core.risk_event_monitor_agent', 'RiskEventMonitorAgent')(cfg.get("RiskEventMonitorAgent")),
            # תוכל להוסיף כאן שורה לכל Agent עתידי בלי לשנות כלום במבנה
        }

    def evaluate(self, symbol, price_df):
        agent_outputs = {}
        for name, agent in self.agents.items():
            try:
                output = agent.analyze(symbol, price_df)
                score = int(output.get("score", 1))
                explanation = output.get("explanation", "")
                details = output.get("details", {})
                agent_outputs[name] = {
                    "score": score,
                    "explanation": explanation,
                    "details": details,
                }
            except Exception as e:
                agent_outputs[name] = {
                    "score": 1,
                    "explanation": f"שגיאת agent: {e}\n{traceback.format_exc()}",
                    "details": {},
                }

        total = 0
        total_weight = 0
        scores = {}
        explanations = {}
        for name, out in agent_outputs.items():
            weight = self.AGENT_WEIGHTS.get(name, 1)
            total += out["score"] * weight
            total_weight += weight
            scores[name] = out["score"]
            explanations[name] = out["explanation"]

        final_score = round(total / total_weight, 2) if total_weight else 0

        return {
            "symbol": symbol,
            "score": final_score,
            "signals": scores,
            "explanations": explanations,
            "recommendation": self.score_to_recommendation(final_score)
        }

    @staticmethod
    def score_to_recommendation(score):
        if score >= 85:
            return "🚀 BUY signal (High Conviction)"
        elif score >= 70:
            return "Strong Setup"
        elif score >= 50:
            return "Watchlist / Medium"
        elif score >= 30:
            return "Weak Signal"
        else:
            return "No Signal"


##### FILE: .\core\analyst_rating_agent.py #####
import requests

class AnalystRatingAgent:
    """
    סוכן דירוג אנליסטים ברמה מקצועית לפי עקרונות מחקר ותוכנית עבודה.
    בודק:
    - פיזור/מספר אנליסטים
    - פער יעד מחיר (upside)
    - דירוג משוקלל חכם
    - סף אמינות
    """

    def __init__(self, config=None):
        self.api_key = (config or {}).get("FMP_API_KEY", "f8avXV34RWqtoYQXSZxVWrDlvhKCwIF5")
        self.base_url = "https://financialmodelingprep.com/api/v3"

    def analyze(self, symbol):
        try:
            url = f"{self.base_url}/analyst-estimates/{symbol.upper()}?apikey={self.api_key}"
            r = requests.get(url, timeout=10)
            data = r.json()
            if not data or not isinstance(data, list) or len(data) == 0:
                return 1

            latest = data[0]
            n_analysts = latest.get("numberAnalystOpinions", 1)
            buy = latest.get("buy", 0)
            hold = latest.get("hold", 0)
            sell = latest.get("sell", 0)
            strongBuy = latest.get("strongBuy", 0)
            strongSell = latest.get("strongSell", 0)
            target_price = latest.get("priceTargetMean", None)
            current_price = latest.get("lastPrice", None)

            # שקלול דירוגים על פי עקרונות מחקר: 
            score_raw = (
                (strongBuy * 2 + buy * 1 + hold * 0.5 - sell * 1 - strongSell * 2)
                / max(1, n_analysts)
            )
            # סקלת המחקר: -2 (רוב חזק למכירה) ... 0 (ממוצע/ניטרלי) ... +2 (קונצנזוס חזק קנייה)
            # נורמליזציה ל-1-100: 0 = 50, 2 = 100, -2 = 1
            score_norm = min(100, max(1, int((score_raw + 2) * 25)))

            # בונוס למניה עם פוטנציאל upside (פער יעד מחיר לעומת מחיר שוק)
            upside = 0
            if target_price and current_price and current_price > 0:
                upside = (target_price - current_price) / current_price * 100
            if upside > 20:
                score_norm = min(100, score_norm + 10)
            elif upside < -10:
                score_norm = max(1, score_norm - 20)

            # אמינות: אם יש פחות מ-5 אנליסטים, הורד ניקוד משמעותית
            if n_analysts < 5:
                score_norm = int(score_norm * 0.5)

            # רצוי: בדיקת שיפור דירוגים לאורך זמן (optional)
            # רמת-על: לבדוק מגמת שינוי בדירוגים בחודשים האחרונים (לא חובה עכשיו)

            return score_norm

        except Exception as ex:
            print(f"[AnalystRatingAgent] ERROR: {type(ex).__name__} | {ex}")
            return 1


##### FILE: .\core\atr_score_agent.py #####
import pandas as pd
import numpy as np

class ATRScoreAgent:
    def __init__(self, config=None):
        self.lookback = config.get("lookback", 14) if config else 14
        self.scale = config.get("scale", 15) if config else 15  # קבוע לנירמול

    def analyze(self, price_df):
        if price_df is None or len(price_df) < self.lookback + 1:
            return 1
        # חישוב True Range לכל יום
        high = price_df["high"]
        low = price_df["low"]
        close = price_df["close"]
        prev_close = close.shift(1)
        tr = pd.concat([
            (high - low),
            (high - prev_close).abs(),
            (low - prev_close).abs()
        ], axis=1).max(axis=1)
        atr = tr.rolling(self.lookback).mean()
        recent_atr = atr.iloc[-1]
        mean_atr = atr.mean()
        # ניקוד: כמה ה-ATR העדכני גבוה מהממוצע
        if mean_atr == 0 or np.isnan(recent_atr):
            score = 1
        else:
            ratio = recent_atr / mean_atr
            score = int(max(1, min(100, 50 + self.scale * (ratio - 1) * 25)))
        return score


##### FILE: .\core\atr_volatility_agent.py #####
import pandas as pd
import numpy as np

class ATRVolatilityAgent:
    def __init__(self, config=None):
        self.lookback = config.get("lookback", 14) if config else 14

    def analyze(self, price_df):
        if price_df is None or len(price_df) < self.lookback + 2:
            return 1
        high = price_df["high"]
        low = price_df["low"]
        close = price_df["close"]
        tr1 = high - low
        tr2 = (high - close.shift()).abs()
        tr3 = (low - close.shift()).abs()
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        atr = tr.rolling(self.lookback).mean()
        # ניקוד יחסי: ATR האחרון ביחס ל־ATR ממוצע (ל־100 יום אחורה)
        recent_atr = atr.iloc[-1] if not atr.empty else 0
        long_term_atr = atr.rolling(100).mean().iloc[-1] if len(atr) >= 100 else atr.mean()
        # היחס (אם אין מספיק היסטוריה)
        ratio = recent_atr / long_term_atr if long_term_atr > 0 else 0
        # נרמל ל־1–100, ערך 1 אם תנודתיות נמוכה, 100 אם חריגה
        score = int(max(1, min(100, ratio * 40 + 60)))  # רגיל סביב 60–80, קפיצה מעל 100%
        return score


##### FILE: .\core\bollinger_squeeze.py #####
import pandas as pd
import numpy as np

class BollingerSqueezeAgent:
    def __init__(self, config=None):
        config = config or {}
        self.window = config.get("window", 20)
        self.sigma = config.get("sigma", 2)
        self.lookback = config.get("lookback", 90)
        self.extreme_pct = config.get("extreme_pct", 0.20)
        self.strong_pct = config.get("strong_pct", 0.35)
        self.width_pct = config.get("width_pct", 0.07)  # רוחב מקסימלי (7%)
        self.squeeze_days = config.get("squeeze_days", 4)

    def analyze(self, price_df):
        """
        קלט: price_df עם close לפחות 90 ימים
        פלט: ניקוד 1–100 לפי דחיסת בולינגר אמיתית
        """
        if len(price_df) < self.window + self.lookback:
            return 1  # לא מספיק נתונים

        close = price_df["close"]
        ma = close.rolling(self.window).mean()
        std = close.rolling(self.window).std()
        upper = ma + self.sigma * std
        lower = ma - self.sigma * std
        width = upper - lower
        width_rel = width / close  # מדד רוחב יחסי למחיר

        # מביטים על self.lookback ימים
        widths = width_rel.iloc[-self.lookback:].dropna()
        if len(widths) < self.sqeeze_days + 10:
            return 1

        # מדדים סטטיסטיים
        median_width = np.median(widths)
        p10_width = np.percentile(widths, 10)

        recent_width = width_rel.iloc[-self.sqeeze_days:]
        avg_recent_width = np.mean(recent_width)

        # ניקוד ראשי לפי עומק הדחיסה
        ratio_to_median = avg_recent_width / median_width
        ratio_to_p10 = avg_recent_width / p10_width if p10_width > 0 else 10

        if avg_recent_width < self.width_pct:
            if ratio_to_median < self.extreme_pct:
                return 100
            elif ratio_to_median < self.strong_pct:
                return 90
            else:
                return 80
        elif ratio_to_median < self.extreme_pct:
            return 90
        elif ratio_to_median < self.strong_pct:
            return 70
        elif ratio_to_median < 0.55:
            return 55
        elif ratio_to_median < 0.75:
            return 40
        else:
            return 10


##### FILE: .\core\breakout_retest_recognizer.py #####
import numpy as np
import pandas as pd

class BreakoutRetestRecognizer:
    """
    Breakout + Retest Recognizer - Ultimate Version with Momentum Detection:
    מזהה פריצה קלאסית (High+Retest+Volume) וגם מהלך Momentum (עלייה חזקה+מחזור).
    """

    def __init__(self, config=None):
        cfg = config or {}
        self.lookback = cfg.get("lookback", 120)
        self.breakout_window = cfg.get("breakout_window", 10)
        self.retest_window = cfg.get("retest_window", 10)
        self.min_breakout_volume_ratio = cfg.get("min_breakout_volume_ratio", 1.5)
        self.gap_percent = cfg.get("gap_percent", 0.015)
        self.retest_margin = cfg.get("retest_margin", 0.02)
        self.success_return = cfg.get("success_return", 0.05)
        # Momentum breakout params
        self.momentum_window = cfg.get("momentum_window", 7)
        self.momentum_return = cfg.get("momentum_return", 0.3)
        self.momentum_volume_ratio = cfg.get("momentum_volume_ratio", 1.5)
        self.debug = cfg.get("debug", False)

    # ... כל הפונקציות בדיוק כמו בקוד הקודם (get_major_highs, detect_breakouts, וכו')

    def get_major_highs(self, highs, window, num=2):
        sorted_highs = highs[-window-1:-1].sort_values(ascending=False).unique()
        return sorted_highs[:num]

    def detect_breakouts(self, df, major_high, window, gap_percent, min_breakout_volume_ratio):
        closes = df['close']
        highs = df['high']
        lows = df['low']
        volumes = df['volume']
        breakouts = []
        avg_volume = volumes.rolling(window=20, min_periods=1).mean()
        for i in range(-window, 0):
            if closes.iloc[i] > major_high and highs.iloc[i] > major_high:
                prev_close = closes.iloc[i-1] if i-1 >= -len(df) else closes.iloc[0]
                gap = (closes.iloc[i] - prev_close) / (prev_close + 1e-8)
                is_gap = gap > gap_percent
                is_high_vol = volumes.iloc[i] > avg_volume.iloc[i] * min_breakout_volume_ratio
                breakouts.append({
                    "idx": i,
                    "price": float(closes.iloc[i]),
                    "volume": float(volumes.iloc[i]),
                    "is_gap": bool(is_gap),
                    "is_high_vol": bool(is_high_vol),
                    "gap_percent": float(gap),
                })
        return breakouts

    def detect_retest(self, df, breakout, margin=0.02, window=10):
        closes = df['close']
        lows = df['low']
        idx = breakout["idx"]
        price = breakout["price"]
        retest_range = (price * (1 - margin), price * (1 + margin))
        for j in range(idx+1, idx+1+window):
            if j >= len(closes): break
            if retest_range[0] <= lows.iloc[j] <= retest_range[1]:
                support_held = closes.iloc[j] >= price * 0.99
                return True, support_held, j
        return False, False, None

    def pattern_before_breakout(self, df, idx, pattern_window=15):
        if idx - pattern_window < 0:
            return False, None
        closes = df['close'].iloc[idx-pattern_window:idx]
        highs = df['high'].iloc[idx-pattern_window:idx]
        lows = df['low'].iloc[idx-pattern_window:idx]
        flag = ((highs.max() - lows.min()) / closes.mean()) < 0.07
        if flag:
            return True, "Flag/Consolidation"
        is_triangle = (highs.diff().mean() < 0) and (lows.diff().mean() > 0)
        if is_triangle:
            return True, "Triangle"
        return False, None

    def momentum_after_breakout(self, df, breakout, window=10, success_return=0.05):
        closes = df['close']
        idx = breakout["idx"]
        if idx+window >= len(closes): return False, 0
        ret = (closes.iloc[idx+window] - closes.iloc[idx]) / closes.iloc[idx]
        return ret > success_return, ret

    def false_breakout(self, df, breakout, major_high, window=10):
        lows = df['low']
        idx = breakout["idx"]
        after_lows = lows.iloc[idx+1:idx+1+window]
        return (after_lows < major_high).any()

    def volume_profile(self, df, price, window=60, band=0.03):
        price_range = (price * (1 - band), price * (1 + band))
        sel = df[(df['close'] >= price_range[0]) & (df['close'] <= price_range[1])]
        total_vol = df['volume'][-window:].sum()
        band_vol = sel['volume'].sum()
        if total_vol == 0: return 0
        return band_vol / total_vol

    def analyze_weekly(self, df):
        df_w = df.copy()
        df_w['week'] = pd.to_datetime(df_w['date']).dt.to_period('W')
        grouped = df_w.groupby('week').agg({'high': 'max', 'low': 'min', 'close': 'last', 'volume': 'sum'}).reset_index()
        high = grouped['high'][-30:-7].max()
        breakouts = (grouped['close'][-7:] > high).sum()
        return breakouts

    def analyze(self, symbol, price_df):
        df = price_df[-self.lookback:].reset_index(drop=True).copy()
        details = {}
        triggers = 0
        reasons = []
        patterns = []

        # --- Breakout קלאסי ---
        major_highs = self.get_major_highs(df['high'], self.lookback-self.breakout_window, num=2)
        details["major_highs"] = [float(h) for h in major_highs]
        all_breakouts = []
        for high in major_highs:
            b_list = self.detect_breakouts(df, high, self.breakout_window, self.gap_percent, self.min_breakout_volume_ratio)
            for b in b_list:
                b["major_high"] = float(high)
                all_breakouts.append(b)
        details["all_breakouts"] = all_breakouts

        successful_breakouts = 0
        best_score = 10
        for b in all_breakouts:
            pattern_flag, pattern_name = self.pattern_before_breakout(df, b["idx"])
            if pattern_flag:
                triggers += 1
                reasons.append(f"{pattern_name} before breakout")
                patterns.append(pattern_name)
            retest_found, retest_held, retest_idx = self.detect_retest(df, b, self.retest_margin, self.retest_window)
            details_key = f"breakout_{b['idx']}"
            details[details_key] = {
                "breakout": b,
                "pattern": pattern_name,
                "retest_found": retest_found,
                "retest_held": retest_held,
                "retest_idx": retest_idx,
            }
            if b["is_gap"]:
                triggers += 1
                reasons.append("Gap breakout")
            if b["is_high_vol"]:
                triggers += 1
                reasons.append("Breakout on high volume")
            if retest_found:
                triggers += 1
                reasons.append("Retest found")
                if retest_held:
                    triggers += 1
                    reasons.append("Retest support held")
            is_false = self.false_breakout(df, b, b["major_high"], self.retest_window)
            if not is_false:
                triggers += 1
                reasons.append("No false breakout after event")
            good_momentum, mret = self.momentum_after_breakout(df, b, self.retest_window, self.success_return)
            details[details_key]["momentum"] = mret
            if good_momentum:
                triggers += 1
                reasons.append(f"Strong momentum: {mret:.1%} return after breakout")
                successful_breakouts += 1
            profile_ratio = self.volume_profile(df, b["price"])
            details[details_key]["profile_ratio"] = profile_ratio
            if profile_ratio > 0.12:
                triggers += 1
                reasons.append("High volume concentration around breakout")
            event_score = 10 + triggers*15
            if event_score > best_score:
                best_score = event_score
            triggers = 0

        try:
            weekly_breakouts = self.analyze_weekly(df)
            details["weekly_breakouts"] = int(weekly_breakouts)
            if weekly_breakouts > 0:
                best_score = min(best_score+10, 100)
                reasons.append("Weekly breakout detected")
        except Exception as e:
            details["weekly_breakouts"] = "Error: " + str(e)

        details["successful_breakouts"] = successful_breakouts
        details["total_breakouts"] = len(all_breakouts)

        # --- Momentum Breakout (תנועה מהירה מאוד באחוזים) ---
        recent_closes = df['close'].tail(self.momentum_window)
        recent_vols = df['volume'].tail(self.momentum_window)
        mom_return = (recent_closes.iloc[-1] - recent_closes.iloc[0]) / (recent_closes.iloc[0] + 1e-8)
        avg_recent_vol = recent_vols.mean()
        avg_vol_all = df['volume'].mean()
        momentum_breakout = False
        mom_score = 0
        if mom_return > self.momentum_return and avg_recent_vol > avg_vol_all * self.momentum_volume_ratio:
            momentum_breakout = True
            mom_score = min(int(mom_return * 180), 95)  # דירוג דינמי
            reasons.append(f"Momentum breakout: {mom_return*100:.1f}% in {self.momentum_window} days")
            best_score = max(best_score, mom_score)
        details["momentum_breakout"] = momentum_breakout
        details["momentum_return"] = mom_return
        details["momentum_avg_recent_vol"] = avg_recent_vol

        best_score = max(min(int(best_score), 100), 10)
        explanation = f"{successful_breakouts}/{len(all_breakouts)} breakout(s) with strong signals. " + ", ".join(reasons) \
            if all_breakouts or momentum_breakout else "No significant breakout detected."

        if self.debug:
            print(f"[BreakoutRetestRecognizer-ULT] {symbol=} score={best_score} details={details}")

        return {
            "score": best_score,
            "explanation": explanation,
            "details": details
        }


##### FILE: .\core\bullish_pattern_spotter.py #####
import pandas as pd

class BullishPatternSpotter:
    def __init__(self, config=None):
        pass

    def analyze(self, price_df):
        # דמו: יחס נר אחרון לעומת ממוצע נרות – ציון גבוה לנר חזק
        close = price_df["close"]
        open_ = price_df["open"]
        score = int(((close.iloc[-1] - open_.iloc[-1]) / open_.iloc[-1]) * 200 + 50)
        return max(1, min(100, score))


##### FILE: .\core\candlestick_agent.py #####
import pandas as pd
import numpy as np

class CandlestickPatternAgent:
    def __init__(self, config=None):
        """
        Candlestick Agent – זיהוי תבניות נרות יפניים ברמת על.
        config: dict עם פרמטרים אופציונליים.
        """
        cfg = config or {}
        self.lookback = cfg.get("lookback", 15)  # כמה ימים לבדוק אחורה
        self.vol_confirm = cfg.get("vol_confirm", 1.3)  # פי כמה מהנפח הממוצע הנדרש לאישור תבנית
        self.ma_period = cfg.get("ma_period", 20)  # ממוצע נע להקשר (תבנית ליד MA חשובה יותר)
        self.strong_patterns = ["Hammer", "Bullish Engulfing", "Morning Star", "Piercing Line",
                                "Shooting Star", "Bearish Engulfing", "Evening Star", "Dark Cloud Cover"]

    def analyze(self, price_df):
        """
        מחזיר ציון 1-100 לפי זיהוי עוצמת תבניות הנר, ווליום יחסי, ומיקום טכני.
        """
        df = price_df.copy().reset_index(drop=True)
        if len(df) < self.lookback + self.ma_period:
            return 1  # לא מספיק נתונים

        df["body"] = abs(df["close"] - df["open"])
        df["range"] = df["high"] - df["low"]
        df["upper_shadow"] = df["high"] - df[["close", "open"]].max(axis=1)
        df["lower_shadow"] = df[["close", "open"]].min(axis=1) - df["low"]
        df["ma"] = df["close"].rolling(self.ma_period).mean()
        df["vol_mean"] = df["volume"].rolling(self.ma_period).mean()

        patterns_scores = []

        for i in range(len(df) - self.lookback, len(df)):
            row = df.iloc[i]
            pattern, base_score = self._detect_pattern(row, df.iloc[max(0, i-3):i+1])

            if pattern:
                # עוצמת תבנית
                score = base_score
                # תוספת ניקוד אם תבנית חזקה וממוקמת מעל/מתחת MA
                if pattern in self.strong_patterns:
                    if abs(row["close"] - row["ma"]) < 0.015 * row["ma"]:
                        score += 13  # מיקום מושלם
                # תוספת לפי גודל גוף/צל
                if pattern in ["Hammer", "Shooting Star"]:
                    if row["body"] < 0.32 * row["range"]:
                        score += 6  # צל חזק מגוף
                # תוספת לווליום תומך
                if row["volume"] > self.vol_confirm * row["vol_mean"]:
                    score += 15
                # ניקוד עד 100
                patterns_scores.append(min(score, 100))
        
        return int(max(patterns_scores) if patterns_scores else 1)

    def _detect_pattern(self, row, window_df):
        """
        מזהה תבניות מפתח. מחזיר (שם התבנית, בסיס ניקוד)
        """
        body = row["body"]
        rng = row["range"]
        upper = row["upper_shadow"]
        lower = row["lower_shadow"]
        open_ = row["open"]
        close = row["close"]

        # Hammer
        if lower > 2 * body and body > 0.1 * rng and upper < 0.3 * rng and close > open_:
            return "Hammer", 50
        # Shooting Star
        if upper > 2 * body and body > 0.1 * rng and lower < 0.3 * rng and close < open_:
            return "Shooting Star", 47
        # Bullish Engulfing
        if len(window_df) >= 2:
            prev = window_df.iloc[-2]
            if prev["close"] < prev["open"] and close > open_ and close > prev["open"] and open_ < prev["close"]:
                return "Bullish Engulfing", 52
            if prev["close"] > prev["open"] and close < open_ and close < prev["open"] and open_ > prev["close"]:
                return "Bearish Engulfing", 50
        # Doji
        if body < 0.09 * rng and upper > 0.35 * rng and lower > 0.35 * rng:
            return "Doji", 34
        # Marubozu
        if body > 0.9 * rng and upper < 0.04 * rng and lower < 0.04 * rng:
            return "Marubozu", 38
        # Morning Star (3 נרות)
        if len(window_df) >= 3:
            a, b, c = window_df.iloc[-3], window_df.iloc[-2], window_df.iloc[-1]
            if (a["close"] < a["open"] and
                b["body"] < 0.3 * b["range"] and
                c["close"] > c["open"] and c["close"] > ((a["close"] + a["open"])/2)):
                return "Morning Star", 55
            if (a["close"] > a["open"] and
                b["body"] < 0.3 * b["range"] and
                c["close"] < c["open"] and c["close"] < ((a["close"] + a["open"])/2)):
                return "Evening Star", 55
        # Piercing Line
        if len(window_df) >= 2:
            prev = window_df.iloc[-2]
            if prev["close"] < prev["open"] and close > open_ and open_ < prev["close"] and close > (prev["open"] + prev["close"])/2:
                return "Piercing Line", 49
            if prev["close"] > prev["open"] and close < open_ and open_ > prev["close"] and close < (prev["open"] + prev["close"])/2:
                return "Dark Cloud Cover", 49

        return None, 0


##### FILE: .\core\charles_core_scorer.py #####
# charles_core_scorer.py

def score_stock(symbol, rsi_flag, float_flag, vol_flag, para_flag):
    explanation = []
    score = 0
    active_signals = 0

    if rsi_flag is not None:
        active_signals += 1
        if rsi_flag:
            score += 1
            explanation.append("✅ RSI מצביע על דחיסה – פוטנציאל תזוזה חזקה בקרוב.")
        else:
            explanation.append("⚠️ RSI לא מצביע על דחיסה.")

    if float_flag is not None:
        active_signals += 1
        if float_flag:
            score += 1
            explanation.append("🔥 Float Pressure גבוה – ייתכן לחץ שורט חיובי.")
        else:
            explanation.append("📉 אין לחץ שורט משמעותי.")

    if para_flag is not None:
        active_signals += 1
        if para_flag:
            score += 1
            explanation.append("📈 תנועה פראבולית חזקה לאחרונה.")
        else:
            explanation.append("🔎 לא זוהתה תנועה פראבולית משמעותית.")

    if vol_flag is not None:
        active_signals += 1
        if vol_flag:
            score += 1
            explanation.append("💤 תנודת נפח נמוכה – מניה 'מבשילה'.")
        else:
            explanation.append("📊 נפח תנודתי – לא מראה דחיסה.")

    # Confidence לפי כמות סוכנים פעילים
    confidence = round((active_signals / 4) * 100)

    # המלצה כללית
    if score == 4:
        recommendation = "🚀 Candidate for Breakout (High Conviction)"
    elif score == 3:
        recommendation = "🔥 Strong Speculative Setup"
    elif score == 2:
        recommendation = "👀 Monitor – partial alignment"
    elif score == 1:
        recommendation = "⚠️ Weak Signal – not tradable alone"
    else:
        recommendation = "❌ No signal – ignore"

    return {
        "symbol": symbol,
        "alpha_score": score,
        "confidence": confidence,
        "recommendation": recommendation,
        "explanation": explanation
    }


##### FILE: .\core\charles_report_formatter.py #####
from email.message import EmailMessage
import os

# יצירת הודעת מייל עם צרופה, ונשמר כקובץ .eml
EMAIL_ADDRESS = "ran819967@gmail.com"
RECIPIENT = "ran819967@gmail.com"
SUBJECT = "📊 דוח Charles - AlphaScore"
BODY = "מצורף הדוח המעודכן כולל גרף AlphaScore לכל מניה. בהצלחה רן!"

# קובץ הדוח מתוך data/
attachment_path = "/mnt/data/data/charles_scan_results_final.xlsx"
attachment_name = os.path.basename(attachment_path)

# יצירת ההודעה
msg = EmailMessage()
msg["Subject"] = SUBJECT
msg["From"] = EMAIL_ADDRESS
msg["To"] = RECIPIENT
msg.set_content(BODY)

# הוספת קובץ מצורף
with open(attachment_path, "rb") as f:
    msg.add_attachment(
        f.read(),
        maintype="application",
        subtype="vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        filename=attachment_name
    )

# שמירת הקובץ כ-eml
output_path = "/mnt/data/charles_report_output.eml"
with open(output_path, "wb") as f:
    f.write(bytes(msg))

output_path


##### FILE: .\core\classic_volume_surge_detector.py #####
import pandas as pd

class ClassicVolumeSurgeDetector:
    def __init__(self, config=None):
        self.window = config.get("window", 20) if config else 20
        self.threshold_sigma = config.get("threshold_sigma", 2) if config else 2
        self.freshness_days = config.get("freshness_days", 5) if config else 5

    def analyze(self, price_df):
        df = price_df.copy()
        df["vol_ma"] = df["volume"].rolling(self.window).mean()
        df["vol_std"] = df["volume"].rolling(self.window).std()
        df["vol_sigma"] = (df["volume"] - df["vol_ma"]) / df["vol_std"]
        last = df.iloc[-self.freshness_days:]
        max_sigma = last["vol_sigma"].max()
        # ניקוד לפי חריגות: כל סטיית תקן = 15 נק', capped
        if max_sigma < self.threshold_sigma:
            return 1
        score = min(100, int((max_sigma - self.threshold_sigma) * 15 + 50))
        return max(1, score)


##### FILE: .\core\earnings_surprise_tracker.py #####
from utils import data_fetcher

class EarningsSurpriseTracker:
    def __init__(self, config=None):
        pass

    def analyze(self, symbol, price_df=None):
        _, surprise_pct = data_fetcher.get_last_earnings_surprise(symbol)
        if surprise_pct is not None:
            score = int(min(100, max(1, surprise_pct + 50)))
            return score
        return 1


##### FILE: .\core\email_report_sender.py #####
from pathlib import Path
import zipfile

# יצירת קובץ email_report_sender.py עם תוכן מעודכן כולל שליחה דרך SMTP
email_report_code = """
import smtplib
import os
from email.message import EmailMessage

# פרטי התחברות ל-Gmail
EMAIL_ADDRESS = "ran819967@gmail.com"
EMAIL_PASSWORD = "glme vomw ouah frrj"

# פרטי המייל
msg = EmailMessage()
msg['Subject'] = '📊 דוח Charles היומי שלך'
msg['From'] = EMAIL_ADDRESS
msg['To'] = EMAIL_ADDRESS
msg.set_content('מצורף בזאת דוח Charles היומי להיום.')

# צירוף הקובץ
file_path = os.path.join('data', 'charles_scan_results_final.xlsx')
with open(file_path, 'rb') as f:
    file_data = f.read()
    file_name = os.path.basename(file_path)

msg.add_attachment(file_data, maintype='application', subtype='vnd.openxmlformats-officedocument.spreadsheetml.sheet', filename=file_name)

# שליחה
with smtplib.SMTP_SSL('smtp.gmail.com', 465) as smtp:
    smtp.login(EMAIL_ADDRESS, EMAIL_PASSWORD)
    smtp.send_message(msg)

print("✅ הדוח נשלח בהצלחה למייל!")
"""

# כתיבה לקובץ
core_path = Path("/mnt/data/Charles_FocusedSpec/core")
core_path.mkdir(parents=True, exist_ok=True)
email_path = core_path / "email_report_sender.py"
email_path.write_text(email_report_code, encoding="utf-8")

email_path.name  # מחזיר את שם הקובץ כדי שאוכל להודיע למשתמש על המיקום שלו



##### FILE: .\core\financial_stability_agent.py #####
from utils import data_fetcher

class FinancialStabilityAgent:
    def __init__(self, config=None):
        self.leverage_weight = config.get("leverage_weight", 0.5) if config else 0.5
        self.liquidity_weight = config.get("liquidity_weight", 0.5) if config else 0.5

    def analyze(self, symbol):
        # שליפת נתוני מאזן אחרון
        balance = data_fetcher.get_balance_sheet(symbol)
        if balance is None or balance.empty:
            return 1

        # חישוב יחס חוב להון
        try:
            total_debt = float(balance.iloc[0].get("totalDebt", 0) or 0)
            total_equity = float(balance.iloc[0].get("totalEquity", 1) or 1)
            leverage = total_debt / total_equity if total_equity > 0 else 1
        except Exception:
            leverage = 1

        # חישוב יחס שוטף (currentRatio)
        try:
            current_assets = float(balance.iloc[0].get("totalCurrentAssets", 0) or 0)
            current_liabilities = float(balance.iloc[0].get("totalCurrentLiabilities", 1) or 1)
            current_ratio = current_assets / current_liabilities if current_liabilities > 0 else 1
        except Exception:
            current_ratio = 1

        # ניקוד איתנות פיננסית: מינימום 1, מקסימום 100
        leverage_score = max(1, min(100, int((1.5 - leverage) * 50)))  # חוב נמוך = ניקוד גבוה
        liquidity_score = max(1, min(100, int((current_ratio - 1) * 50 + 50)))  # יחס שוטף מעל 1=ניקוד גבוה
        score = int(self.leverage_weight * leverage_score + self.liquidity_weight * liquidity_score)
        return max(1, min(100, score))


##### FILE: .\core\float_pressure_evaluator.py #####
class FloatPressureEvaluator:
    def __init__(self, config=None):
        pass

    def analyze(self, symbol, price_df=None):
        # דמו: שלוף %float מהמערכת שלך! כאן תמיד 30 לצורך דוגמה
        float_pct = 30
        score = int(float_pct * 3.3)
        return max(1, min(100, score))


##### FILE: .\core\gap_detector_ultimate.py #####
"""
GapDetectorUltimate (Full Research/Production Grade)
-----------------------------------------------------
Agent detects and scores price gaps as early signals of potential breakouts,
with the following features:
- Detects single, multiple, consecutive, and rare gaps (percentile based)
- Analyzes gap direction, magnitude (raw & normalized), volume confirmation,
  trend context (pre/post gap), follow-through, and 'gap & trap' reversals
- Returns full-feature scoring (1-100), feature dictionary, and full event history
- Supports ML feature extraction and graphical visualization for analytics
Based on: 'Early Signs of Large Uptrends in Stocks', business plan, and advanced quant research.
"""
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

class GapDetectorUltimate:
    def __init__(self, config=None):
        cfg = config or {}
        self.gap_threshold_pct = cfg.get("gap_threshold_pct", 5)
        self.rare_gap_percentile = cfg.get("rare_gap_percentile", 92)
        self.max_gap_days = cfg.get("max_gap_days", 3)
        self.min_volume_ratio = cfg.get("min_volume_ratio", 1.25)
        self.follow_through_days = cfg.get("follow_through_days", 5)
        self.reversal_penalty = cfg.get("reversal_penalty", 0.4)
        self.trend_lookback = cfg.get("trend_lookback", 15)
        self.history_window = cfg.get("history_window", 90)
        self.verbose = cfg.get("verbose", False)

    def _calculate_gap_scores(self, df, verbose=False):
        gap_events = []
        # Historical gap stats for normalization
        historical_gaps = 100 * (df["open"].iloc[1:self.history_window].values - df["close"].iloc[:self.history_window-1].values) / (df["close"].iloc[:self.history_window-1].values + 1e-9)
        rare_gap_thresh = np.percentile(np.abs(historical_gaps), self.rare_gap_percentile)

        for idx in range(1, len(df)):
            prev_close = df.iloc[idx-1]["close"]
            cur_open = df.iloc[idx]["open"]
            cur_close = df.iloc[idx]["close"]
            cur_high = df.iloc[idx]["high"]
            cur_low = df.iloc[idx]["low"]
            cur_vol = df.iloc[idx]["volume"]
            prev_vol = df.iloc[idx-1]["volume"]

            gap_pct = 100 * (cur_open - prev_close) / prev_close

            # Only up-gaps for this agent (modify for down-gap strategy if needed)
            if gap_pct < self.gap_threshold_pct:
                continue

            # Volume confirmation
            avg_vol = df["volume"].iloc[max(0, idx-5):idx].mean() if idx >= 5 else prev_vol
            volume_spike = cur_vol / (avg_vol + 1e-9)

            # Follow-through analysis
            future_closes = df["close"].iloc[idx:min(idx+self.follow_through_days+1, len(df))]
            post_gap_return = ((future_closes.max() - cur_open) / cur_open) * 100 if not future_closes.empty else 0

            # Consecutive gaps check
            cons_gap = 1
            for d in range(1, self.max_gap_days+1):
                if idx-d < 1: break
                prev_gap = 100 * (df.iloc[idx-d]["open"] - df.iloc[idx-d-1]["close"]) / (df.iloc[idx-d-1]["close"] + 1e-9)
                if prev_gap >= self.gap_threshold_pct:
                    cons_gap += 1
                else:
                    break

            # Gap & trap: does price fill the gap soon after?
            gap_filled = 0
            for f in range(1, min(3, len(df)-idx)):
                if df.iloc[idx+f]["low"] < prev_close:
                    gap_filled = 1
                    break

            # Rare gap detection (percentile score)
            gap_rarity = min(1.0, np.abs(gap_pct) / (rare_gap_thresh+1e-9))

            # Trend context (pre-gap and post-gap)
            trend_start = max(0, idx-self.trend_lookback)
            pretrend = (df["close"].iloc[trend_start:idx].mean() - df["close"].iloc[trend_start]) / (df["close"].iloc[trend_start]+1e-9)
            posttrend = (df["close"].iloc[min(len(df)-1, idx+self.follow_through_days)] - cur_open) / (cur_open+1e-9) if idx+self.follow_through_days < len(df) else 0

            # Feature dictionary (for ML, analytics, explainability)
            feat = {
                "date": str(df.iloc[idx].get("date", idx)),
                "gap_pct": gap_pct,
                "gap_rarity": gap_rarity,
                "volume_spike": volume_spike,
                "follow_through_return": post_gap_return,
                "consecutive_gaps": cons_gap,
                "gap_filled": gap_filled,
                "pre_gap_trend": pretrend,
                "post_gap_trend": posttrend,
            }

            # Score composition (all components weighted and explained)
            score = (
                min(gap_pct, 15) / 15 * 30 +                     # Gap magnitude
                gap_rarity * 25 +                                # Rare gaps bonus
                min(1, volume_spike / self.min_volume_ratio) * 15 + # Volume confirmation
                min(1, post_gap_return / 10) * 10 +              # Follow-through (capped at 10%)
                (cons_gap-1)/self.max_gap_days * 10 +            # Consecutive gaps
                (1 if pretrend > 0 else 0) * 5 +                 # Pre-gap uptrend
                (1 if posttrend > 0 else 0) * 5                  # Post-gap uptrend
            )
            if gap_filled: score *= self.reversal_penalty

            feat["score"] = score
            gap_events.append(feat)
            if verbose:
                print(f"Gap@{feat['date']}: gap={gap_pct:.2f}%, rarity={gap_rarity:.2f}, vol_spk={volume_spike:.2f}, post_gap_ret={post_gap_return:.2f}%, cons_gap={cons_gap}, filled={gap_filled}, score={score:.1f}")

        return gap_events

    def analyze(self, symbol, price_df, **kwargs):
        """
        Full gap detection analysis.
        Args:
            symbol: str
            price_df: DataFrame (MUST include: open, close, high, low, volume, [date])
        Returns:
            int: score (1–100), event_features (list of dict)
        """
        if price_df is None or len(price_df) < 20:
            return 1, []

        gap_events = self._calculate_gap_scores(price_df, verbose=self.verbose)
        if not gap_events:
            return 1, []

        # Use max event score (most significant gap), or aggregate as you wish
        final_score = int(max(1, min(100, max(ev["score"] for ev in gap_events))))
        return final_score, gap_events

    def extract_feature_matrix(self, price_df):
        """
        For ML use – returns pd.DataFrame with all feature vectors for detected gaps
        """
        events = self._calculate_gap_scores(price_df)
        return pd.DataFrame(events)

    def plot_gaps(self, price_df, gap_events=None):
        """
        Plots price with detected gaps for visual analytics.
        """
        if gap_events is None:
            _, gap_events = self.analyze("?", price_df)
        plt.figure(figsize=(14, 6))
        plt.plot(price_df["close"].values, label="Close Price")
        gap_idxs = [int(e["date"]) if str(e["date"]).isdigit() else price_df.index.get_loc(pd.to_datetime(e["date"])) for e in gap_events]
        plt.scatter(gap_idxs, price_df["close"].iloc[gap_idxs], color='r', marker='^', s=120, label="Detected Gaps")
        plt.title("Gap Detector Ultimate – Price & Gaps")
        plt.legend()
        plt.show()


##### FILE: .\core\geopolitical_risk_monitor.py #####
from utils import data_fetcher

class GeopoliticalRiskMonitor:
    def __init__(self, config=None):
        pass

    def analyze(self, symbol, price_df=None):
        geo = data_fetcher.get_geo_risk_score(symbol)
        score = int(100 - geo * 100)
        return max(1, min(100, score))


##### FILE: .\core\golden_cross_detector.py #####
import pandas as pd

class GoldenCrossDetector:
    def __init__(self, config=None):
        self.short_window = config.get("short_window", 50) if config else 50
        self.long_window = config.get("long_window", 200) if config else 200
        self.freshness_days = config.get("freshness_days", 7) if config else 7

    def analyze(self, price_df):
        df = price_df.copy()
        df["ma_short"] = df["close"].rolling(self.short_window).mean()
        df["ma_long"] = df["close"].rolling(self.long_window).mean()

        cross_days = (df["ma_short"] > df["ma_long"])
        cross_events = cross_days & (~cross_days.shift(1, fill_value=False))
        cross_idx = df.index[cross_events].tolist()

        if not cross_idx:
            return 1  # No cross, ציון מינימלי

        last_cross_idx = cross_idx[-1]
        days_since_cross = (df.index[-1] - last_cross_idx).days if hasattr(df.index[-1], "days") else len(df) - df.index.get_loc(last_cross_idx) - 1

        # טריות האירוע
        if days_since_cross <= self.freshness_days:
            base_score = 100
        elif days_since_cross <= self.freshness_days * 4:
            base_score = 70
        else:
            base_score = 40

        # חיזוק לפי עוצמת החצייה (פער היחסי)
        try:
            short_val = df.loc[last_cross_idx, "ma_short"]
            long_val = df.loc[last_cross_idx, "ma_long"]
            gap = abs(short_val - long_val) / long_val * 100
            gap_score = min(30, gap)
        except:
            gap_score = 0

        score = int(min(100, base_score + gap_score))
        return score


##### FILE: .\core\growth_scanner.py #####
from utils import data_fetcher

class GrowthConsistencyScanner:
    def __init__(self, config=None):
        pass

    def analyze(self, symbol, price_df=None):
        growth = data_fetcher.get_growth_rate(symbol)
        score = int(min(100, max(1, growth + 50)))
        return score


##### FILE: .\core\high_conviction_orchestrator.py #####
from core.multi_agent_validator import MultiAgentCrossValidator

class HighConvictionSignalOrchestrator:
    def __init__(self):
        """אתחול האורקסטרטור עם מודול הולידציה לחצייה."""
        self.validator = MultiAgentCrossValidator()

    def decide(self, analysis_result):
        """
        קבלת החלטה לגבי Conviction גבוה.
        analysis_result - מילון התוצאה ממנוע הניקוד (המכיל "score", "signals", "recommendation").
        מחזיר True אם האיתות נחשב בעל ביטחון גבוה, False אם לא.
        """
        score = analysis_result["score"]
        signals = analysis_result["signals"]
        recommendation = analysis_result["recommendation"]
        # תחילה, בדוק אם המערכת המליצה על HIGH conviction על סמך ציון
        high_score_flag = (score >= 4 and "HIGH" in recommendation)
        if not high_score_flag:
            return False  # אם גם ככה לא סווג כ-High במנוע, ודאי לא נסמן ככזה
        # אם כן, נבדוק אם יש סתירות מהותיות בין הסיגנלים או סיכונים:
        conflict = self.validator.detect_conflicts(signals)
        if conflict:
            # אם יש קונפליקט משמעותי, לא נגדיר כביטחון גבוה
            return False
        # בנוסף, אם יש סיכון גיאופוליטי פעיל, נזהר:
        if signals.get("Geo_risk"):
            return False
        # אם עבר את כל הבדיקות - זה אות בעל ביטחון גבוה באמת
        return True


##### FILE: .\core\macd_momentum_detector.py #####
import pandas as pd

class MACDMomentumDetector:
    def __init__(self, config=None):
        self.fast = config.get("fast", 12) if config else 12
        self.slow = config.get("slow", 26) if config else 26
        self.signal = config.get("signal", 9) if config else 9
        self.freshness_days = config.get("freshness_days", 5) if config else 5

    def analyze(self, price_df):
        df = price_df.copy()
        df["ema_fast"] = df["close"].ewm(span=self.fast, adjust=False).mean()
        df["ema_slow"] = df["close"].ewm(span=self.slow, adjust=False).mean()
        df["macd"] = df["ema_fast"] - df["ema_slow"]
        df["macd_signal"] = df["macd"].ewm(span=self.signal, adjust=False).mean()
        df["macd_hist"] = df["macd"] - df["macd_signal"]

        # ניתוח המומנטום (חיובי = שורי)
        hist = df["macd_hist"].iloc[-self.freshness_days:]
        pos = (hist > 0).sum()
        neg = (hist < 0).sum()
        last_hist = hist.iloc[-1]

        # חישוב ניקוד
        if last_hist > 0:
            base = 60 + min(40, int(last_hist * 200))   # סיגנל חזק
            score = min(100, base + pos * 5 - neg * 5)
        else:
            score = max(1, 50 + int(last_hist * 100))   # סיגנל שלילי מוחלש

        return int(score)


##### FILE: .\core\midterm_momentum_agent.py #####
import pandas as pd

class MidtermMomentumAgent:
    def __init__(self, config=None):
        self.short_period = config.get("short_period", 21) if config else 21   # חודש
        self.long_period = config.get("long_period", 63) if config else 63     # 3 חודשים
        self.weight_short = config.get("weight_short", 0.5) if config else 0.5

    def analyze(self, price_df):
        if price_df is None or len(price_df) < self.long_period:
            return 1

        # ממוצע נע קצר וארוך
        price_df = price_df.copy()
        price_df["SMA_short"] = price_df["close"].rolling(window=self.short_period).mean()
        price_df["SMA_long"] = price_df["close"].rolling(window=self.long_period).mean()

        # שינוי אחוזי מחיר ל-3 ו-6 חודשים
        last_price = price_df["close"].iloc[-1]
        try:
            change_short = (last_price / price_df["close"].iloc[-self.short_period] - 1) * 100
        except Exception:
            change_short = 0
        try:
            change_long = (last_price / price_df["close"].iloc[-self.long_period] - 1) * 100
        except Exception:
            change_long = 0

        # ניקוד מומנטום: 1-100
        score_short = max(1, min(100, int(change_short + 50)))
        score_long = max(1, min(100, int(change_long + 50)))
        score = int(self.weight_short * score_short + (1 - self.weight_short) * score_long)
        return max(1, min(100, score))


##### FILE: .\core\moving_average_pressure_bot.py #####
import pandas as pd

class MovingAveragePressureBot:
    def __init__(self, config=None):
        self.lookback = config.get("lookback", 20) if config else 20

    def analyze(self, price_df):
        close = price_df["close"]
        ma = close.rolling(self.lookback).mean()
        last = close.iloc[-1]
        last_ma = ma.iloc[-1]
        # קרוב לממוצע – לחץ גבוה
        score = 100 - int(abs(last - last_ma) / last_ma * 100)
        return max(1, min(100, score))


##### FILE: .\core\multi_agent_validator.py #####
class MultiAgentCrossValidator:
    def __init__(self):
        """אתחול מודול ולידציה חוצה-סוכנים (אין פרמטרים קבועים בשלב זה)."""
        pass

    def detect_conflicts(self, signals):
        """
        בדיקת סתירות בין אותות הסוכנים.
        מקבל מילון signals {שם_סוכן: Boolean} ומחזיר True אם נמצאה סתירה משמעותית, אחרת False.
        """
        conflicts = []
        # דוגמה 1: סנטימנט שלילי (אם היה מדד כזה) מול דפוס טכני חיובי חזק.
        # (במקרה שלנו, אם אין סנטימנט חיובי כלל אבל מספר רב של אותות טכניים חיוביים)
        technical_signals = ["RSI_compression", "Volume_tension", "Breakout_retest", "Support_zone_strength", "MA_pressure", "Bullish_pattern"]
        positive_technicals = sum(1 for sig in technical_signals if signals.get(sig))
        if positive_technicals >= 3 and signals.get("Sentiment") is False:
            conflicts.append("Strong technicals but no positive sentiment")
        # דוגמה 2: אות שלילי טכני מול חיוביים אחרים (למשל Parabolic=True אבל שאר חיוביים)
        if signals.get("Parabolic_move") and positive_technicals >= 2:
            conflicts.append("Overbought technical (parabolic) vs other positive signals")
        # דוגמה 3: הייפ חברתי גבוה אבל יסודות חלשים (לדוגמה Social hype=True אבל Growth/Valuation False)
        if signals.get("Sentiment") and signals.get("Social_hype") and not signals.get("Consistent_growth") and not signals.get("Valuation_anomaly"):
            conflicts.append("High social hype but fundamentals do not support valuation")
        # דוגמה 4: סיכון גיאופוליטי קיים למרות סימנים חיוביים אחרים
        if signals.get("Geo_risk") and positive_technicals >= 2:
            conflicts.append("Geopolitical risk present despite positive signals")
        # אפשר להוסיף עוד כללים כנדרש...
        # החזרת True אם יש לפחות קונפליקט אחד
        return len(conflicts) > 0


##### FILE: .\core\news_catalyst_agent.py #####
import requests

class NewsCatalystAgent:
    def __init__(self, keywords=None, lookback_days=7):
        """
        אתחול הסוכן.
        keywords - רשימת מילות מפתח לאיתור חדשות 'טובות' (ברירת מחדל רשימה כללית).
        lookback_days - טווח זמן לבדיקת חדשות אחרונות (7 ימים ברירת מחדל).
        """
        if keywords is None:
            keywords = ["beats earnings", "FDA approval", "acquisition", "merger", "partnership", "upgrade"]
        self.keywords = keywords
        self.lookback_days = lookback_days

    def analyze(self, symbol):
        """
        זיהוי חדשות קטליסטיות עבור הטיקר.
        מחזיר True אם נמצאה ידיעה חיובית משמעותית לאחרונה, אחרת False.
        """
        try:
            # שימוש ב-FMP API לקבלת חדשות אחרונות עבור הטיקר
            api_key = "<FMP_API_KEY>"  # יש להחליף במפתח API אמיתי
            url = (f"https://financialmodelingprep.com/api/v3/stock_news?tickers={symbol}"
                   f"&limit=10&apikey={api_key}")
            resp = requests.get(url, timeout=5)
        except Exception as e:
            return False
        if resp.status_code != 200:
            return False
        news_items = resp.json()
        if not isinstance(news_items, list):
            return False
        # עבור כל כותרת/תוכן חדשות, בדוק אם מכיל אחת ממילות המפתח
        for item in news_items:
            title = item.get("title", "").lower()
            summary = item.get("text", "").lower()
            for kw in self.keywords:
                if kw in title or kw in summary:
                    return True
        return False


##### FILE: .\core\parabolic_agent.py #####
# core/parabolic_agent.py

import numpy as np
import pandas as pd

class ParabolicAgent:
    """
    Parabolic Move Detector – גרסת על (מחקר/עסקי)
    מזהה תנועות פראבוליות חדות (run up, climax), בדגש על זוית, רצף, Convexity, נפח.
    """
    def __init__(self, config=None):
        cfg = config or {}
        self.min_days = cfg.get("min_days", 5)  # מינימום ימים לפריצה
        self.max_window = cfg.get("max_window", 30)
        self.convexity_threshold = cfg.get("convexity_threshold", 1.2)  # יחס עקום
        self.angle_threshold = cfg.get("angle_threshold", 65)  # מעלות מינימום
        self.volume_spike_zscore = cfg.get("volume_spike_zscore", 2)
        self.debug = cfg.get("debug", False)

    def _calc_angle(self, closes):
        # חישוב זוית התנועה בגרף log (דינמיקה אמיתית)
        y = np.log(closes.values)
        x = np.arange(len(closes))
        slope = np.polyfit(x, y, 1)[0]
        angle = np.degrees(np.arctan(slope))
        return angle

    def _calc_convexity(self, closes):
        # חישוב קמוריות (convexity) של התנועה
        x = np.arange(len(closes))
        y = closes.values
        coeffs = np.polyfit(x, y, 2)
        convexity = coeffs[0]
        return convexity

    def detect_parabolic_run(self, price_df):
        closes = price_df['close'][-self.max_window:]
        highs = price_df['high'][-self.max_window:]
        lows = price_df['low'][-self.max_window:]
        volumes = price_df['volume'][-self.max_window:]

        # 1. בדוק כמה ימים ברצף עלייה (streak)
        streak = 0
        for i in range(1, len(closes)):
            if closes.iloc[-i] > closes.iloc[-i-1]:
                streak += 1
            else:
                break

        # 2. זוית כללית ב-log scale
        angle = self._calc_angle(closes)
        # 3. קמוריות
        convexity = self._calc_convexity(closes)
        # 4. סף סגולי – קפיצה מינ' ב-X ימים
        price_return = closes.iloc[-1] / closes.iloc[0] - 1
        # 5. Spike במחזור (ימים אחרונים)
        vol = volumes[-self.min_days:]
        mean_vol = volumes[:-self.min_days].mean() if len(volumes) > self.min_days else volumes.mean()
        std_vol = volumes[:-self.min_days].std() if len(volumes) > self.min_days else volumes.std()
        spike_z = (vol.mean() - mean_vol) / (std_vol + 1e-8)
        volume_spike = spike_z > self.volume_spike_zscore

        # סף מחקרי – כל התנאים יחד מעידים על ריצה פראבולית
        triggers = 0
        reasons = []

        if streak >= self.min_days:
            triggers += 1
            reasons.append(f"{streak} days up")
        if angle > self.angle_threshold:
            triggers += 1
            reasons.append(f"Sharp angle {angle:.1f}°")
        if abs(convexity) > self.convexity_threshold:
            triggers += 1
            reasons.append(f"Strong convexity {convexity:.2f}")
        if price_return > 0.20:  # לפחות 20% עלייה בחלון קצר
            triggers += 1
            reasons.append(f"{price_return*100:.1f}% return")
        if volume_spike:
            triggers += 1
            reasons.append(f"Volume spike z={spike_z:.2f}")

        details = {
            "streak": streak,
            "angle": angle,
            "convexity": convexity,
            "price_return": price_return,
            "volume_spike_z": spike_z,
            "volume_spike": volume_spike,
            "max_window": self.max_window
        }

        # דירוג 1–100: כל טריגר חזק – ציון גבוה, רק עם כל התנאים = 100
        score = 20
        if triggers >= 4:
            score = 100
        elif triggers == 3:
            score = 80
        elif triggers == 2:
            score = 60
        elif triggers == 1:
            score = 40

        explanation = ", ".join(reasons) if reasons else "No strong parabolic move detected."

        if self.debug:
            print(f"[ParabolicAgent-ULT] score={score}, triggers={triggers}, reasons={reasons}, details={details}")

        return score, explanation, details

    def analyze(self, symbol, price_df):
        try:
            score, explanation, details = self.detect_parabolic_run(price_df)
        except Exception as e:
            return {
                "score": 1,
                "explanation": f"Error: {e}",
                "details": {}
            }
        return {
            "score": int(score),
            "explanation": explanation,
            "details": details
        }


##### FILE: .\core\rsi_sniffer.py #####
import pandas as pd
import numpy as np

class RSICompressionSniffer:
    """
    Ultimate RSI Compression Detector:
    - Multi-Timeframe RSI (e.g., 14d daily + 14w weekly)
    - Squeeze detection via rolling std
    - Divergence & Cross-check with volume squeeze
    - Full config & scoring
    Returns: dict - {'score': 1-100, 'explanation': str, 'details': dict}
    """
    def __init__(self, config=None):
        cfg = config or {}
        self.rsi_lookbacks = cfg.get("lookbacks", [14, 21])
        self.timeframes = cfg.get("timeframes", ["1d", "1w"])
        self.sqz_std_threshold = cfg.get("squeeze_std_threshold", 2.0)
        self.rsi_high = cfg.get("rsi_high", 70)
        self.rsi_low = cfg.get("rsi_low", 30)
        self.sqz_length = cfg.get("squeeze_length", 10)
        self.min_cross_triggers = cfg.get("min_cross_triggers", 2)
        self.debug = cfg.get("debug", False)

    @staticmethod
    def calc_rsi(close, period):
        delta = close.diff()
        gain = delta.where(delta > 0, 0)
        loss = -delta.where(delta < 0, 0)
        avg_gain = gain.rolling(window=period, min_periods=period).mean()
        avg_loss = loss.rolling(window=period, min_periods=period).mean()
        rs = avg_gain / (avg_loss + 1e-9)
        rsi = 100 - (100 / (1 + rs))
        return rsi

    @staticmethod
    def calc_volume_squeeze(volume, window=20):
        # Bollinger Bands Squeeze on volume
        rolling_mean = volume.rolling(window).mean()
        rolling_std = volume.rolling(window).std()
        upper = rolling_mean + 2 * rolling_std
        lower = rolling_mean - 2 * rolling_std
        squeeze = (upper - lower) / rolling_mean
        return squeeze

    def analyze(self, symbol, price_df):
        results = []
        for lookback in self.rsi_lookbacks:
            close = price_df['close']
            rsi = self.calc_rsi(close, lookback)
            rolling_std = rsi.rolling(self.sqz_length).std()
            squeeze_points = rolling_std < self.sqz_std_threshold
            overbought = (rsi > self.rsi_high).any()
            oversold = (rsi < self.rsi_low).any()
            vol_squeeze = self.calc_volume_squeeze(price_df['volume'])
            volume_tight = (vol_squeeze.tail(self.sqz_length) < 0.2).all()
            result = {
                "lookback": lookback,
                "rsi_squeeze": bool(squeeze_points.tail(1).iloc[0]),
                "overbought": bool(overbought),
                "oversold": bool(oversold),
                "volume_tight": bool(volume_tight),
            }
            results.append(result)
            if self.debug:
                print(f"[RSI-Sniffer] {lookback=}: Squeeze={result['rsi_squeeze']} Overbought={overbought} Oversold={oversold} Volume Tight={volume_tight}")

        cross_triggers = sum(
            r["rsi_squeeze"] and r["volume_tight"] for r in results
        )
        # ציון 100 = כל הקריטריונים התקיימו, פחות – מדורג
        if cross_triggers >= self.min_cross_triggers:
            score = 100
            explanation = f"Detected {cross_triggers} strong RSI+Volume squeezes."
        elif cross_triggers == 1:
            score = 60
            explanation = "Single squeeze event – medium confidence."
        else:
            score = 20
            explanation = "No significant RSI squeeze detected."
        return {
            "score": int(score),
            "explanation": explanation,
            "details": {
                "symbol": symbol,
                "rsi_results": results,
                "cross_triggers": cross_triggers
            }
        }


##### FILE: .\core\sentiment_scorer.py #####
from utils import data_fetcher

class SentimentScorer:
    def __init__(self, config=None):
        pass

    def analyze(self, symbol, price_df=None):
        sentiment = data_fetcher.get_sentiment_score(symbol)
        score = int((sentiment + 1) * 50)
        return max(1, min(100, score))


##### FILE: .\core\short_squeeze_analyzer.py #####
class ShortSqueezePotentialAnalyzer:
    def __init__(self, config=None):
        pass

    def analyze(self, symbol, price_df=None):
        # דמו: שלוף נתון שורט, כאן נקבע 15%
        short_pct = 15
        score = int(short_pct * 6.6)
        return max(1, min(100, score))


##### FILE: .\core\social_media_hype_scanner.py #####
import requests
import datetime

class SocialMediaHypeScanner:
    def __init__(self, subreddit="wallstreetbets", lookback_days=7, min_mentions=50):
        """
        אתחול הסוכן.
        subreddit - סאב-רדיט למעקב (ברירת מחדל wallstreetbets).
        lookback_days - מספר ימים אחרונים לבדיקת האזכורים (ברירת מחדל 7).
        min_mentions - סף מינימלי של אזכורים בתקופה להיחשב "באזז" (ברירת מחדל 50).
        """
        self.subreddit = subreddit
        self.lookback_days = lookback_days
        self.min_mentions = min_mentions

    def analyze(self, symbol):
        """
        בדיקת 'הייפ' ברשתות חברתיות עבור הטיקר.
        מחזיר True אם מספר האזכורים בפורום הנבחר בשבוע האחרון גבוה באופן חשוד, אחרת False.
        """
        end_time = int(datetime.datetime.utcnow().timestamp())
        start_time = end_time - self.lookback_days * 24 * 60 * 60
        url = (f"https://api.pushshift.io/reddit/search/submission/?q={symbol}"
               f"&after={start_time}&before={end_time}&subreddit={self.subreddit}")
        try:
            response = requests.get(url, timeout=5)
        except Exception as e:
            return False
        if response.status_code != 200:
            return False
        data = response.json().get("data", [])
        mention_count = len(data)
        if mention_count >= self.min_mentions:
            return True
        else:
            return False


##### FILE: .\core\support_zone_strength_detector.py #####
import numpy as np
import pandas as pd

def compute_volume_profile(price_df, price_step=0.005):
    lows = price_df['low']
    highs = price_df['high']
    volumes = price_df['volume']
    price_min = lows.min()
    price_max = highs.max()
    bins = np.arange(price_min, price_max + price_step, price_step)
    profile = {b: 0 for b in bins}
    for _, row in price_df.iterrows():
        low, high, vol = row['low'], row['high'], row['volume']
        p_lo = int((low - price_min) / price_step)
        p_hi = int((high - price_min) / price_step)
        for j in range(p_lo, p_hi + 1):
            b = price_min + j * price_step
            if b in profile:
                profile[b] += vol / (p_hi - p_lo + 1)
    pf = pd.DataFrame({'price': list(profile.keys()), 'volume': list(profile.values())})
    return pf

def classify_candle(open_, high, low, close, prev_open=None, prev_close=None):
    body = close - open_
    range_ = high - low
    if range_ == 0:
        return ""
    # Hammer
    if body > 0 and (open_ - low) > 2 * abs(body) and (high - close) < 0.3 * range_:
        return "hammer"
    # Bullish engulfing
    if prev_open is not None and prev_close is not None:
        if (prev_close < prev_open) and (close > open_) and (close > prev_open) and (open_ < prev_close):
            return "bullish_engulfing"
    # Doji
    if abs(close - open_) < 0.1 * range_:
        return "doji"
    return ""

def detect_morning_star(df, idx):
    if idx < 2:
        return False
    o1, c1 = df.iloc[idx - 2]['open'], df.iloc[idx - 2]['close']
    o2, c2 = df.iloc[idx - 1]['open'], df.iloc[idx - 1]['close']
    o3, c3 = df.iloc[idx]['open'], df.iloc[idx]['close']
    cond1 = c1 < o1 and (o2 > c1 or c2 > c1)
    cond2 = abs(c2 - o2) < 0.5 * abs(c1 - o1)
    cond3 = c3 > o3 and c3 > ((c1 + o1) / 2)
    return cond1 and cond2 and cond3

def find_double_bottom(lows, threshold=0.01):
    # מזהה אם יש שני שפל קרובים ברמה דומה
    idxs = lows.nsmallest(2).index.values
    if len(idxs) < 2:
        return False, []
    lvl1, lvl2 = lows.iloc[idxs[0]], lows.iloc[idxs[1]]
    if abs(lvl1 - lvl2) < threshold * ((lvl1 + lvl2) / 2):
        return True, idxs
    return False, []

def find_double_top(highs, threshold=0.01):
    idxs = highs.nlargest(2).index.values
    if len(idxs) < 2:
        return False, []
    lvl1, lvl2 = highs.iloc[idxs[0]], highs.iloc[idxs[1]]
    if abs(lvl1 - lvl2) < threshold * ((lvl1 + lvl2) / 2):
        return True, idxs
    return False, []

class SupportResistanceZoneStrengthDetector:
    def __init__(self, config=None):
        cfg = config or {}
        self.window = cfg.get("window", 50)
        self.sensitivity = cfg.get("sensitivity", 0.012)
        self.min_touches = cfg.get("min_touches", 2)
        self.profile_radius = cfg.get("profile_radius", 0.012)
        self.min_score = cfg.get("min_score", 30)
        self.debug = cfg.get("debug", False)
        self.plot = cfg.get("plot", False)

    def find_local_minima(self, series):
        # ממחזרים את האינדקס לחלון קטן (reset_index)
        series = series.reset_index(drop=True)
        return series[(series.shift(1) > series) & (series.shift(-1) > series)]

    def find_local_maxima(self, series):
        series = series.reset_index(drop=True)
        return series[(series.shift(1) < series) & (series.shift(-1) < series)]

    def advanced_false_break(self, series, closes, lvl, idxs, is_support=True):
        n = 0
        for i in idxs:
            if i < 0 or i >= len(series):
                continue
            if is_support:
                if series.iloc[i] < lvl * (1 - 2 * self.profile_radius) and closes.iloc[i] > lvl:
                    n += 1
            else:
                if series.iloc[i] > lvl * (1 + 2 * self.profile_radius) and closes.iloc[i] < lvl:
                    n += 1
        return n >= 2

    def analyze(self, symbol, price_df):
        if price_df.shape[0] < self.window + 10:
            return {"score": 0, "support_zones": [], "resistance_zones": [], "zone_strength": 0, "explanation": "Insufficient data."}

        # reset_index ל־window
        window_df = price_df.iloc[-self.window:].reset_index(drop=True)
        lows = window_df['low']
        closes = window_df['close']
        highs = window_df['high']
        opens = window_df['open']
        volumes = window_df['volume']
        volume_profile = compute_volume_profile(price_df)

        # איתור Double Bottom/Top (כל החלון)
        is_double_bottom, db_idxs = find_double_bottom(lows)
        is_double_top, dt_idxs = find_double_top(highs)

        zones_supp, zones_res = [], []

        # --- Support Zones ---
        support_candidates = self.find_local_minima(lows)
        for lvl in support_candidates.unique():
            if np.isnan(lvl): continue
            mask = (lows >= lvl * (1 - self.profile_radius)) & (lows <= lvl * (1 + self.profile_radius))
            touches = mask.sum()
            if touches < self.min_touches: continue
            idxs = np.where(mask)[0]
            vol_near = volumes.iloc[idxs].mean() if len(idxs) > 0 else 0
            avg_vol = volumes.mean()
            prof_vol = volume_profile[
                (volume_profile['price'] >= lvl * (1 - self.profile_radius)) &
                (volume_profile['price'] <= lvl * (1 + self.profile_radius))
            ]['volume'].sum()
            volume_spike = vol_near > avg_vol * 1.3 or prof_vol > volume_profile['volume'].mean() * 1.5
            idx_last = idxs[-1] if len(idxs) > 0 else None
            price_rebound = None
            if idx_last is not None and (idx_last + 3) < len(window_df):
                after_touch = closes.iloc[idx_last + 1:idx_last + 4]
                rebound = (after_touch.max() - lows.iloc[idx_last]) / lows.iloc[idx_last]
                price_rebound = rebound
            false_break = self.advanced_false_break(lows, closes, lvl, idxs, is_support=True)
            candle_type = ""
            if idx_last is not None:
                i = idx_last
                o, h, l, c = opens.iloc[i], highs.iloc[i], lows.iloc[i], closes.iloc[i]
                prev_o, prev_c = (opens.iloc[i - 1], closes.iloc[i - 1]) if i > 0 else (None, None)
                candle_type = classify_candle(o, h, l, c, prev_o, prev_c)
                if detect_morning_star(window_df, i):
                    candle_type = "morning_star"
            # דפוס Double Bottom
            double_bottom = False
            if is_double_bottom and any((abs(lvl - lows.iloc[j]) < 0.01 * lvl for j in db_idxs if 0 <= j < len(lows))):
                double_bottom = True

            score = 25 if touches > 2 else 10
            if volume_spike: score += 20
            if price_rebound and price_rebound > 0.045: score += 15
            if candle_type in ["hammer", "bullish_engulfing", "doji", "morning_star"]: score += 10
            if false_break: score += 15
            if double_bottom: score += 10
            if score > 100: score = 100

            zones_supp.append({
                "type": "support",
                "level": float(lvl),
                "touches": int(touches),
                "volume_near_zone": int(vol_near),
                "profile_vol": int(prof_vol),
                "volume_spike": bool(volume_spike),
                "price_rebound": float(price_rebound) if price_rebound is not None else None,
                "false_break": bool(false_break),
                "candle": candle_type,
                "double_bottom": double_bottom,
                "score": int(score)
            })

        # --- Resistance Zones ---
        resistance_candidates = self.find_local_maxima(highs)
        for lvl in resistance_candidates.unique():
            if np.isnan(lvl): continue
            mask = (highs >= lvl * (1 - self.profile_radius)) & (highs <= lvl * (1 + self.profile_radius))
            touches = mask.sum()
            if touches < self.min_touches: continue
            idxs = np.where(mask)[0]
            vol_near = volumes.iloc[idxs].mean() if len(idxs) > 0 else 0
            avg_vol = volumes.mean()
            prof_vol = volume_profile[
                (volume_profile['price'] >= lvl * (1 - self.profile_radius)) &
                (volume_profile['price'] <= lvl * (1 + self.profile_radius))
            ]['volume'].sum()
            volume_spike = vol_near > avg_vol * 1.3 or prof_vol > volume_profile['volume'].mean() * 1.5
            idx_last = idxs[-1] if len(idxs) > 0 else None
            price_rebound = None
            if idx_last is not None and (idx_last + 3) < len(window_df):
                after_touch = closes.iloc[idx_last + 1:idx_last + 4]
                rebound = (highs.iloc[idx_last] - after_touch.min()) / highs.iloc[idx_last]
                price_rebound = rebound
            false_break = self.advanced_false_break(highs, closes, lvl, idxs, is_support=False)
            candle_type = ""
            if idx_last is not None:
                i = idx_last
                o, h, l, c = opens.iloc[i], highs.iloc[i], lows.iloc[i], closes.iloc[i]
                prev_o, prev_c = (opens.iloc[i - 1], closes.iloc[i - 1]) if i > 0 else (None, None)
                candle_type = classify_candle(o, h, l, c, prev_o, prev_c)
            # דפוס Double Top
            double_top = False
            if is_double_top and any((abs(lvl - highs.iloc[j]) < 0.01 * lvl for j in dt_idxs if 0 <= j < len(highs))):
                double_top = True

            score = 25 if touches > 2 else 10
            if volume_spike: score += 20
            if price_rebound and price_rebound > 0.045: score += 15
            if candle_type in ["hammer", "bullish_engulfing", "doji"]: score += 10
            if false_break: score += 15
            if double_top: score += 10
            if score > 100: score = 100

            zones_res.append({
                "type": "resistance",
                "level": float(lvl),
                "touches": int(touches),
                "volume_near_zone": int(vol_near),
                "profile_vol": int(prof_vol),
                "volume_spike": bool(volume_spike),
                "price_rebound": float(price_rebound) if price_rebound is not None else None,
                "false_break": bool(false_break),
                "candle": candle_type,
                "double_top": double_top,
                "score": int(score)
            })

        # תצוגה
        df_supp = pd.DataFrame(zones_supp)
        df_res = pd.DataFrame(zones_res)
        min_score = self.min_score

        print("\n--- אזורי תמיכה חזקים (score >= {}) ---".format(min_score))
        if not df_supp.empty:
            print(df_supp.loc[df_supp["score"] >= min_score][["level", "touches", "volume_spike", "candle", "double_bottom", "price_rebound", "false_break", "profile_vol", "score"]])
        else:
            print("No strong support zones.")

        print("\n--- אזורי תמיכה חלשים (score < {}) ---".format(min_score))
        if not df_supp.empty:
            print(df_supp.loc[df_supp["score"] < min_score][["level", "touches", "volume_spike", "candle", "double_bottom", "price_rebound", "false_break", "profile_vol", "score"]])
        else:
            print("No weak support zones.")

        print("\n--- אזורי התנגדות חזקים (score >= {}) ---".format(min_score))
        if not df_res.empty:
            print(df_res.loc[df_res["score"] >= min_score][["level", "touches", "volume_spike", "candle", "double_top", "price_rebound", "false_break", "profile_vol", "score"]])
        else:
            print("No strong resistance zones.")

        print("\n--- אזורי התנגדות חלשים (score < {}) ---".format(min_score))
        if not df_res.empty:
            print(df_res.loc[df_res["score"] < min_score][["level", "touches", "volume_spike", "candle", "double_top", "price_rebound", "false_break", "profile_vol", "score"]])
        else:
            print("No weak resistance zones.")

        # plot both
        if self.plot:
            import matplotlib.pyplot as plt
            plt.figure(figsize=(12, 6))
            plt.plot(price_df["date"], price_df["close"], label="Close")
            for _, z in df_supp.loc[df_supp["score"] >= min_score].iterrows():
                plt.axhline(z["level"], color='g', linestyle="--", alpha=0.6, label=f"Support {z['level']:.2f} (score {z['score']})")
                if z["volume_spike"]:
                    plt.scatter(price_df["date"].iloc[-self.window:], [z["level"]] * self.window, marker='v', color='green', s=30, label=f"Spike {z['level']:.2f}")
                if z["candle"] in ["hammer", "bullish_engulfing", "doji", "morning_star"]:
                    plt.scatter(price_df["date"].iloc[-self.window:], [z["level"]] * self.window, marker='*', color='yellow', s=40, label=f"{z['candle']} @ {z['level']:.2f}")
            for _, z in df_res.loc[df_res["score"] >= min_score].iterrows():
                plt.axhline(z["level"], color='r', linestyle="--", alpha=0.6, label=f"Resistance {z['level']:.2f} (score {z['score']})")
            plt.title(f"Support/Resistance Zones for {symbol}")
            plt.xlabel("Date")
            plt.ylabel("Price")
            plt.legend()
            plt.tight_layout()
            plt.show()

        return {
            "support_zones": zones_supp,
            "resistance_zones": zones_res
        }


##### FILE: .\core\ticker_batch_runner.py #####
import pandas as pd
import json
from utils import data_fetcher
from core.alpha_score_engine import AlphaScoreEngine
from core.high_conviction_orchestrator import HighConvictionSignalOrchestrator
from core.trade_execution_preparer import TradeExecutionPreparer

# טוען את הגדרות הפרמטרים
with open("config/settings.json", "r") as f:
    config = json.load(f)

# אתחול מנוע הניקוד עם ההגדרות
engine = AlphaScoreEngine(config)
orchestrator = HighConvictionSignalOrchestrator()
trade_preparer = TradeExecutionPreparer()

# קריאת רשימת הסימולים מקובץ CSV
tickers = []
try:
    tickers_list = pd.read_csv("data/tickers.csv", header=None)
    tickers = tickers_list[0].tolist()
except Exception as e:
    # גיבוי: אם כשל בקריאה, הגדרת רשימה ידנית לדוגמה
    tickers = ["AAPL", "TSLA", "GME"]

results = []
for symbol in tickers:
    try:
        # שליפת נתוני מחיר אחרונים (נניח 100 ימי מסחר אחרונים)
        price_df = data_fetcher.get_price_data(symbol, interval="1day", outputsize=100)
    except Exception as e:
        print(f"Error fetching data for {symbol}: {e}")
        continue
    # הפעלת המנוע לקבלת תוצאת הניתוח
    result = engine.evaluate(symbol, price_df)
    results.append(result)
    # הדפסת סיכום תוצאה למסך
    score = result["score"]
    reco = result["recommendation"]
    print(f"{symbol}: Score = {score}, Recommendation = {reco}")
    # הדפסת פירוט האותות (True/False לכל סוכן)
    for sig, val in result["signals"].items():
        sign = "++" if val else "--"
        print(f"    {sign} {sig} = {'TRUE' if val else 'FALSE'}")
    # בדיקת Conviction גבוה באמצעות האורקסטרטור
    if orchestrator.decide(result):
        print(f"*** {symbol}: HIGH conviction signal confirmed! ***")
        # הכנת פקודת מסחר לדוגמה
        trade_preparer.prepare_order(symbol, action="BUY")
    print("--------------------------------------------------")

# שמירת התוצאות לקובץ CSV
if results:
    df_results = pd.DataFrame([{
        "symbol": res["symbol"],
        "score": res["score"],
        "recommendation": res["recommendation"],
        **res["signals"]
    } for res in results])
    df_results.to_csv("outputs/charles_scan_results.csv", index=False)
    print("Results saved to outputs/charles_scan_results.csv")
else:
    print("No results to save.")


##### FILE: .\core\trade_execution_preparer.py #####
class TradeExecutionPreparer:
    def __init__(self, default_quantity=100):
        """
        אתחול מכין הפקודות.
        default_quantity - כמות מניות ברירת מחדל להכנה (100 למשל).
        """
        self.default_quantity = default_quantity

    def prepare_order(self, symbol, action="BUY"):
        """
        הכנת פקודת מסחר אוטומטית.
        symbol - סימול המניה.
        action - סוג הפעולה ("BUY" או "SELL"), ברירת מחדל BUY.
        מחזיר מבנה פקודה (למשל מילון) שניתן לשלוח דרך ממשק ברוקר.
        """
        order = {
            "symbol": symbol,
            "action": action,
            "type": "MARKET",
            "quantity": self.default_quantity
        }
        # כאן ניתן היה להוסיף פרמטרים כמו price limit וכו' אם לא Market.
        print(f"[TradeExecutionPreparer] Prepared order: {order}")
        return order


##### FILE: .\core\valuation_detector.py #####
from utils import data_fetcher

class ValuationAnomalyDetector:
    def __init__(self, config=None):
        pass

    def analyze(self, symbol, price_df=None):
        pe, sector_pe = data_fetcher.get_pe_ratio(symbol)
        if pe is not None and sector_pe != 0:
            rel = (sector_pe - pe) / sector_pe
            score = int(min(100, max(1, rel * 100 + 50)))
            return score
        return 1


##### FILE: .\core\volatility_score_agent.py #####
import pandas as pd

class VolatilityScoreAgent:
    def __init__(self, config=None):
        self.window = config.get("window", 21) if config else 21  # ברירת מחדל: חודש
        self.scale = config.get("scale", 2.5) if config else 2.5  # קבוע לשקלול ניקוד

    def analyze(self, price_df):
        if price_df is None or len(price_df) < self.window + 1:
            return 1

        # חישוב תשואה יומית
        returns = price_df["close"].pct_change().dropna()
        # סטיית תקן בתשואה בחלון נתון
        recent_vol = returns[-self.window:].std()
        # השוואה לממוצע רב-שנתי (או כל התקופה)
        total_vol = returns.std()

        # ניקוד: תנודתיות יחסית לעבר, סקלת 1–100
        if total_vol == 0:
            score = 1
        else:
            ratio = recent_vol / total_vol
            # קידוד: יחס מעל 1 = תנודתיות גוברת
            score = int(max(1, min(100, 50 + self.scale * (ratio - 1) * 25)))
        return score


##### FILE: .\core\volume_tension_meter.py #####
# core/volume_tension_meter.py

import numpy as np
import pandas as pd

class VolumeTensionMeter:
    """
    Ultimate Volume Tension Meter – גרסת מחקר/תוכנית עסקית:
    - זיהוי Volume Contraction Pattern (VCP), Squeeze, Spike.
    - ניתוח multi-timeframe (יומי + שבועי).
    - בדיקת cross עם price action (דשדוש, breakout).
    - ציון חכם 1–100, הסבר, פרטי חישוב מלאים.
    """

    def __init__(self, config=None):
        cfg = config or {}
        self.window = cfg.get("window", 20)
        self.squeeze_threshold = cfg.get("squeeze_threshold", 0.25)
        self.expansion_threshold = cfg.get("expansion_threshold", 0.80)
        self.vcp_cycles = cfg.get("vcp_cycles", 3)  # מס' מחזורי התכווצות
        self.vcp_drop = cfg.get("vcp_drop", 0.7)    # ירידה מובהקת (30%)
        self.spike_zscore = cfg.get("spike_zscore", 2.5)
        self.debug = cfg.get("debug", False)

    def detect_vcp(self, volume, cycles=3, drop=0.7):
        """ מזהה כמה גלי התכווצות מחזוריים (VCP) התרחשו לאחרונה """
        lows = []
        last_mean = volume[-self.window:].mean()
        # עבור כל חלון, בדוק האם המחזור ירד ב-30%+ מהשיא בחלון קודם
        idx = len(volume) - self.window * cycles
        if idx < 0: return 0
        for i in range(cycles):
            window_slice = volume[idx + i*self.window : idx + (i+1)*self.window]
            if len(window_slice) < self.window: break
            max_vol = window_slice.max()
            min_vol = window_slice.min()
            if min_vol < max_vol * drop:
                lows.append(True)
            else:
                lows.append(False)
        return sum(lows)

    def detect_spike(self, volume):
        """ מזהה Spike במחזור (Z-score גבוה) """
        if len(volume) < self.window * 2:
            return False, 0
        mean = volume[-self.window*2:-self.window].mean()
        std = volume[-self.window*2:-self.window].std()
        last = volume.iloc[-1]
        zscore = (last - mean) / (std + 1e-8)
        return (zscore > self.spike_zscore), zscore

    def analyze_price_action(self, price_df, window=20):
        """ בדיקת דשדוש/התכווצות תנועה (Tight Range) """
        close = price_df['close']
        high = price_df['high']
        low = price_df['low']
        range_ = (high - low).rolling(window).mean()
        volatility = close.pct_change().rolling(window).std()
        tight = (range_.iloc[-1] < range_.mean()*0.8) and (volatility.iloc[-1] < volatility.mean()*0.8)
        return tight

    def rolling_bandwidth(self, volume):
        rolling_mean = volume.rolling(self.window).mean()
        rolling_std = volume.rolling(self.window).std()
        upper = rolling_mean + 2 * rolling_std
        lower = rolling_mean - 2 * rolling_std
        band_width = (upper - lower) / (rolling_mean + 1e-8)
        return band_width

    def analyze(self, symbol, price_df):
        volume = price_df['volume']
        # 1. בדיקת Squeeze ו-Expansion (Bollinger)
        band_width = self.rolling_bandwidth(volume)
        last_band = band_width.iloc[-1]
        rolling_mean = volume.rolling(self.window).mean()
        last_volume = volume.iloc[-1]

        # 2. בדיקת VCP (שלושה גלי התכווצות)
        vcp_score = self.detect_vcp(volume, cycles=self.vcp_cycles, drop=self.vcp_drop)

        # 3. Spike במחזור (Z-score)
        spike, spike_z = self.detect_spike(volume)

        # 4. בדיקת Price Action – האם דשדוש/טווח צר
        tight_range = self.analyze_price_action(price_df, window=self.window)

        # 5. multi-timeframe (בדיקה שבועית בסיסית)
        weekly_squeeze = False
        try:
            price_df_week = price_df.copy()
            price_df_week['week'] = pd.to_datetime(price_df_week['date']).dt.to_period('W')
            weekly_volume = price_df_week.groupby('week')['volume'].sum()
            weekly_band = self.rolling_bandwidth(weekly_volume)
            weekly_squeeze = (weekly_band.iloc[-1] < self.squeeze_threshold)
        except Exception:
            pass

        details = {
            "last_band_width": float(last_band) if not np.isnan(last_band) else None,
            "last_volume": int(last_volume) if not np.isnan(last_volume) else None,
            "vcp_score": vcp_score,
            "spike": spike,
            "spike_zscore": float(spike_z),
            "tight_range": tight_range,
            "weekly_squeeze": weekly_squeeze,
            "window": self.window,
        }

        # *** דירוג חכם 1-100 ***
        triggers = 0
        reasons = []

        if last_band < self.squeeze_threshold:
            triggers += 1
            reasons.append("Daily volume squeeze")
        if weekly_squeeze:
            triggers += 1
            reasons.append("Weekly volume squeeze")
        if vcp_score >= self.vcp_cycles:
            triggers += 1
            reasons.append(f"VCP: {vcp_score} contraction cycles")
        if spike:
            triggers += 1
            reasons.append(f"Recent volume spike (z={spike_z:.2f})")
        if tight_range:
            triggers += 1
            reasons.append("Tight price range")

        # חישוב ניקוד מדורג
        score = 20  # בסיס
        if triggers >= 4:
            score = 100
        elif triggers == 3:
            score = 85
        elif triggers == 2:
            score = 65
        elif triggers == 1:
            score = 40
        else:
            score = 10

        explanation = ", ".join(reasons) if reasons else "No significant volume contraction or spike detected."

        if self.debug:
            print(f"[VolumeTensionMeter-ULTIMATE] {symbol=} score={score} triggers={triggers} reasons={reasons} details={details}")

        return {
            "score": int(score),
            "explanation": explanation,
            "details": details
        }


##### FILE: .\core\vwap_agent.py #####
import pandas as pd
import numpy as np

class VWAPAgent:
    def __init__(self, config=None):
        """
        אתחול הסוכן, אפשר להגדיר סף z-score חריג (ברירת מחדל: 1.5 סטיות תקן).
        config: {"zscore_threshold": 1.5}
        """
        cfg = config or {}
        self.zscore_threshold = cfg.get("zscore_threshold", 1.5)

    def analyze(self, price_df):
        """
        ניתוח האם המניה נסחרת מעל/מתחת ל-VWAP ברמת חריגה מובהקת.
        מחזיר ציון 1-100: 100=קניה קיצונית, 1=מכירה קיצונית, 50=שוק ניטרלי.
        """
        if len(price_df) < 20:
            return 50  # אין מספיק נתונים

        # חישוב VWAP יומי (volume-weighted average price)
        price_df["TP"] = (price_df["high"] + price_df["low"] + price_df["close"]) / 3
        vwap = (price_df["TP"] * price_df["volume"]).cumsum() / price_df["volume"].cumsum()
        price_df["vwap"] = vwap

        # חישוב סטיית תקן של המרחק מה-VWAP ב-20 הימים האחרונים
        price_df["dist"] = price_df["close"] - price_df["vwap"]
        last_20 = price_df["dist"].tail(20)
        mean = last_20.mean()
        std = last_20.std(ddof=0)
        latest_dist = price_df["dist"].iloc[-1]

        # חישוב Z-score של המרחק מה-VWAP
        if std == 0:
            z = 0
        else:
            z = (latest_dist - mean) / std

        # ציון - סקאלה 1-100 (100 = קניה קיצונית, 1 = מכירה קיצונית, 50 = ניטרלי)
        # חריגה מעל סף --> קניה, מתחת --> מכירה
        if z > self.zscore_threshold:
            score = int(100 - min(40, abs(z * 20)))
        elif z < -self.zscore_threshold:
            score = int(1 + min(40, abs(z * 20)))
        else:
            score = 50 + int(z * 20)  # אזור ניטרלי
        # הגבלת הציון 1-100
        score = max(1, min(100, score))
        return score


##### FILE: .\core\vwap_trend_agent.py #####
import pandas as pd

class VWAPTrendAgent:
    def __init__(self, config=None):
        """
        config: 
            {
                "anchored_event_index": None/מספר (למשל יום דוח),
                "weight_sync": 0.7,   # משקל לפריצה מסונכרנת
                "weight_avwap": 0.3   # משקל לפריצה לעומת anchored vwap
            }
        """
        cfg = config or {}
        self.anchor_idx = cfg.get("anchored_event_index", None)
        self.weight_sync = cfg.get("weight_sync", 0.7)
        self.weight_avwap = cfg.get("weight_avwap", 0.3)

    def _calc_vwap(self, price_df, window):
        price = price_df["close"].iloc[-window:]
        volume = price_df["volume"].iloc[-window:]
        vwap = (price * volume).cumsum() / volume.cumsum()
        # הסדרה תתחיל עם Nan עבור קנדלים קודמים
        full_vwap = pd.Series([None]*(len(price_df)-window) + list(vwap), index=price_df.index)
        return full_vwap

    def _calc_anchored_vwap(self, price_df, anchor_idx):
        # מחושב מהנקודה המוגדרת (למשל יום דוח)
        volume = price_df["volume"].iloc[anchor_idx:]
        pv = (price_df["close"].iloc[anchor_idx:] * volume).cumsum()
        cum_vol = volume.cumsum()
        avwap = pv / cum_vol
        result = pd.Series([None]*anchor_idx + list(avwap), index=price_df.index)
        return result

    def analyze(self, price_df):
        """
        מחזיר ציון 1-100: 
        - 100 = פריצה מתואמת בו זמנית של VWAP יומי/שבועי/חודשי + המחיר מעל Anchored VWAP
        - 1 = מתחת לכולם, או תבנית שלילית (למשל rejection חזק מכל VWAP)
        """
        n = len(price_df)
        if n < 21:
            return 1  # לא מספיק נתונים

        # חישוב VWAP בכמה טווחים (קביעת חלונות לדוגמה)
        vwap_daily   = self._calc_vwap(price_df, window=1)
        vwap_weekly  = self._calc_vwap(price_df, window=5)
        vwap_monthly = self._calc_vwap(price_df, window=21)

        # Anchored VWAP (נק' דוח/שפל/אירוע)
        avwap = None
        if self.anchor_idx is not None and self.anchor_idx < n:
            avwap = self._calc_anchored_vwap(price_df, self.anchor_idx)
        last_idx = price_df.index[-1]

        price = price_df["close"].iloc[-1]

        # סיגנל: המחיר מעל כל VWAP (sync breakout)
        vwap_sync_break = (
            price > vwap_daily.iloc[-1] and 
            price > vwap_weekly.iloc[-1] and 
            price > vwap_monthly.iloc[-1]
        )

        # סיגנל Anchored (אם יש נק' עיגון)
        avwap_signal = False
        if avwap is not None and avwap.iloc[-1] is not None:
            avwap_signal = price > avwap.iloc[-1]
        
        # מדד איכות/רמת breakout: אפשר לכייל גם לפי כמה רחוק מה-vwap
        sync_score = 100 if vwap_sync_break else max(1, int(100 * ((price - min(vwap_daily.iloc[-1], vwap_weekly.iloc[-1], vwap_monthly.iloc[-1])) / price))
        avwap_score = 100 if avwap_signal else 30 if avwap is not None else 1

        # משקלול
        total_score = int(self.weight_sync * sync_score + self.weight_avwap * avwap_score)
        return max(1, min(total_score, 100))



##### FILE: .\core\v_reversal_agent.py #####
import pandas as pd
import numpy as np

class VReversalAgent:
    def __init__(self, config=None):
        """
        V-Reversal advanced agent – מחיר, ווליום, ופרופיל V אידאלי.
        config:
            - window: כמה ימים לבדוק (ברירת מחדל: 25)
            - pivot_lookback: מינימום ימי pivot (שפל) [ברירת מחדל: 3]
            - min_drop_pct: אחוז ירידה נדרש לפני היפוך V
            - min_rise_pct: אחוז עליה נדרשת מהשפל
            - min_vol_increase: עליה בווליום ביום המהפך (ברירת מחדל: 1.5)
            - v_min_speed: יחס מהירות עליה/ירידה
        """
        cfg = config or {}
        self.window = cfg.get("window", 25)
        self.pivot_lookback = cfg.get("pivot_lookback", 3)
        self.min_drop_pct = cfg.get("min_drop_pct", 8)
        self.min_rise_pct = cfg.get("min_rise_pct", 7)
        self.min_vol_increase = cfg.get("min_vol_increase", 1.5)
        self.v_min_speed = cfg.get("v_min_speed", 1.4)

    def analyze(self, price_df):
        """
        מחזיר ציון 1-100: 100 = V reversal מושלם (מהירות, עוצמה, ווליום, קרבה לתמיכה).
        60-80 = V reversal חזק, 40-59 = תיקון V סביר, 1-30 = אין V.
        """
        df = price_df.copy().reset_index(drop=True)
        if len(df) < self.window + self.pivot_lookback + 3:
            return 1  # לא מספיק נתונים

        recent = df[-self.window:].copy()
        close = recent["close"].values
        vol = recent["volume"].values

        # מציאת נקודת שפל לוקאלית
        piv_idx = np.argmin(close)
        pivot = close[piv_idx]

        # תנאי: השפל לא צמוד לקצה (לפחות pivot_lookback ימים מכל צד)
        if piv_idx < self.pivot_lookback or piv_idx > len(close) - self.pivot_lookback - 1:
            return 1

        # חלק 1: ירידה לפני השפל
        high_before = np.max(close[:piv_idx+1])
        drop_pct = 100 * (high_before - pivot) / high_before if high_before > 0 else 0

        # חלק 2: עלייה אחרי השפל
        high_after = np.max(close[piv_idx:])
        rise_pct = 100 * (high_after - pivot) / pivot if pivot > 0 else 0

        # מהירות: נרות מהשיא לשפל ומהשפל לשיא
        drop_speed = piv_idx
        rise_speed = len(close) - piv_idx - 1
        speed_ratio = (rise_pct / rise_speed) / (drop_pct / drop_speed) if drop_speed > 0 and rise_speed > 0 else 0

        # ווליום ביום היפוך V לעומת ממוצע 10 ימים קודמים
        vol_before = np.mean(vol[max(0, piv_idx-10):piv_idx]) if piv_idx >= 2 else 1
        vol_ratio = vol[piv_idx] / vol_before if vol_before > 0 else 1

        # הצללת נר (V אמיתי = נר היפוך רחב, נר שאחרי עולה)
        reversal_candle = (
            (recent.iloc[piv_idx]["close"] > recent.iloc[piv_idx]["open"]) and
            (recent.iloc[piv_idx+1]["close"] > recent.iloc[piv_idx+1]["open"]) and
            (recent.iloc[piv_idx+1]["close"] > recent.iloc[piv_idx]["close"])
        )

        # תמיכה: האם השפל קרוב לשפל 60 יום/נמוך שנתי
        try:
            low_60d = df["close"][-60:].min()
            support_proximity = abs(pivot - low_60d) / low_60d < 0.03
        except Exception:
            support_proximity = False

        # ניקוד: כל תנאי מוסיף ניקוד – שילוב חוזק V, ווליום, proximity, reversal candle
        score = 1
        if (drop_pct > self.min_drop_pct and rise_pct > self.min_rise_pct and speed_ratio > self.v_min_speed):
            score += 40 + int(min(drop_pct, rise_pct) * min(1.5, speed_ratio))  # חוזק התבנית
            if vol_ratio > self.min_vol_increase:
                score += 20  # ווליום פורץ
            if reversal_candle:
                score += 18
            if support_proximity:
                score += 12
        elif drop_pct > 0.7 * self.min_drop_pct and rise_pct > 0.7 * self.min_rise_pct:
            score += 25 + int(min(drop_pct, rise_pct) * 0.8)

        # Limit score range
        score = int(min(score, 100))
        return score


##### FILE: .\data\charles_scan_results.csv #####
Symbol,RSI_STD,FloatRatio,Parabolic10d,VolatilityRatio,AlphaScore,Confidence,Recommendation,Explanation
AAPL,9.73,,8.067962152813097,0.28217424366205623,1,75,⚠️ Weak Signal – not tradable alone,⚠️ RSI לא מצביע על דחיסה. | 🔎 לא זוהתה תנועה פראבולית משמעותית. | 💤 תנודת נפח נמוכה – מניה 'מבשילה'.
MSFT,5.72,,2.259287023155082,0.3123789925669624,2,75,👀 Monitor – partial alignment,✅ RSI מצביע על דחיסה – פוטנציאל תזוזה חזקה בקרוב. | 🔎 לא זוהתה תנועה פראבולית משמעותית. | 💤 תנודת נפח נמוכה – מניה 'מבשילה'.
GOOGL,7.3,,3.0694668820678475,0.5076636732123198,1,75,⚠️ Weak Signal – not tradable alone,✅ RSI מצביע על דחיסה – פוטנציאל תזוזה חזקה בקרוב. | 🔎 לא זוהתה תנועה פראבולית משמעותית. | 📊 נפח תנודתי – לא מראה דחיסה.
TSLA,9.17,,-1.987269057599762,0.3828856390534738,0,75,❌ No signal – ignore,⚠️ RSI לא מצביע על דחיסה. | 🔎 לא זוהתה תנועה פראבולית משמעותית. | 📊 נפח תנודתי – לא מראה דחיסה.
NVDA,5.62,,8.09045916964532,0.1916043433726201,2,75,👀 Monitor – partial alignment,✅ RSI מצביע על דחיסה – פוטנציאל תזוזה חזקה בקרוב. | 🔎 לא זוהתה תנועה פראבולית משמעותית. | 💤 תנודת נפח נמוכה – מניה 'מבשילה'.
AMZN,7.28,,3.482025221155645,0.47091690202673603,1,75,⚠️ Weak Signal – not tradable alone,✅ RSI מצביע על דחיסה – פוטנציאל תזוזה חזקה בקרוב. | 🔎 לא זוהתה תנועה פראבולית משמעותית. | 📊 נפח תנודתי – לא מראה דחיסה.
META,7.21,,2.558316685111469,0.27726677621507495,2,75,👀 Monitor – partial alignment,✅ RSI מצביע על דחיסה – פוטנציאל תזוזה חזקה בקרוב. | 🔎 לא זוהתה תנועה פראבולית משמעותית. | 💤 תנודת נפח נמוכה – מניה 'מבשילה'.
QBTS,15.22,,1.7186505410566493,0.26834546397738884,1,75,⚠️ Weak Signal – not tradable alone,⚠️ RSI לא מצביע על דחיסה. | 🔎 לא זוהתה תנועה פראבולית משמעותית. | 💤 תנודת נפח נמוכה – מניה 'מבשילה'.
QSI,7.85,,13.142857142857142,0.518683874449453,1,75,⚠️ Weak Signal – not tradable alone,✅ RSI מצביע על דחיסה – פוטנציאל תזוזה חזקה בקרוב. | 🔎 לא זוהתה תנועה פראבולית משמעותית. | 📊 נפח תנודתי – לא מראה דחיסה.
PLTR,9.64,,-5.601600457273509,0.3785926799038102,0,75,❌ No signal – ignore,⚠️ RSI לא מצביע על דחיסה. | 🔎 לא זוהתה תנועה פראבולית משמעותית. | 📊 נפח תנודתי – לא מראה דחיסה.


##### FILE: .\data\manual_float_data.csv #####
symbol,float_ratio
AAPL,0.156
TSLA,0.178
NVDA,0.124
MSFT,0.191
AMZN,0.143


##### FILE: .\data\tickers.csv #####
QBTS


##### FILE: .\log\log.txt #####
❌ TwelveData error for https://api.twelvedata.com/float?symbol=AAPL&apikey=1674fddb50d947cc97e7caafecd246a4: HTTPSConnectionPool(host='api.twelvedata.com', port=443): Max retries exceeded with url: /time_series?symbol=https%3A%2F%2Fapi.twelvedata.com%2Ffloat%3Fsymbol%3DAAPL%26apikey%3D1674fddb50d947cc97e7caafecd246a4&interval=1day&outputsize=5000&apikey=1674fddb50d947cc97e7caafecd246a4&format=JSON&start_date=2023-07-03&end_date=2025-07-02 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Basic Constraints of CA cert not marked critical (_ssl.c:1028)')))
❌ TwelveData error for https://api.twelvedata.com/float?symbol=AAPL&apikey=1674fddb50d947cc97e7caafecd246a4: HTTPSConnectionPool(host='api.twelvedata.com', port=443): Max retries exceeded with url: /time_series?symbol=https%3A%2F%2Fapi.twelvedata.com%2Ffloat%3Fsymbol%3DAAPL%26apikey%3D1674fddb50d947cc97e7caafecd246a4&interval=1day&outputsize=5000&apikey=1674fddb50d947cc97e7caafecd246a4&format=JSON&start_date=2023-07-03&end_date=2025-07-02 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Basic Constraints of CA cert not marked critical (_ssl.c:1028)')))


##### FILE: .\outputs\agent_status_report.csv #####
﻿symbol,RSICompressionSniffer,VolumeTensionMeter,ParabolicAgent,BreakoutRetestRecognizer,SupportZoneStrengthDetector,MovingAveragePressureBot,BullishPatternSpotter,FloatPressureEvaluator,ShortSqueezePotentialAnalyzer,EarningsSurpriseTracker,GrowthConsistencyScanner,ValuationAnomalyDetector,SentimentScorer,GeopoliticalRiskMonitor
AAPL,OK_FALSE,OK_FALSE,OK_FALSE,OK_FALSE,OK_TRUE,OK_FALSE,OK_FALSE,OK_FALSE,OK_FALSE,OK_FALSE,OK_FALSE,OK_FALSE,OK_FALSE,OK_FALSE
TSLA,OK_FALSE,OK_FALSE,OK_FALSE,OK_FALSE,OK_FALSE,OK_FALSE,OK_FALSE,OK_FALSE,OK_FALSE,OK_FALSE,OK_TRUE,OK_FALSE,OK_FALSE,OK_FALSE
NVDA,OK_FALSE,OK_FALSE,OK_FALSE,OK_TRUE,OK_TRUE,OK_FALSE,OK_FALSE,OK_FALSE,OK_FALSE,OK_FALSE,OK_TRUE,OK_FALSE,OK_FALSE,OK_FALSE


##### FILE: .\outputs\charles_scan_results.csv #####
symbol,score,recommendation,RSI_compression,Volume_tension,Parabolic_move,Breakout_retest,Support_zone_strength,MA_pressure,Bullish_pattern,Float_pressure,Short_squeeze,Earnings_surprise,Consistent_growth,Valuation_anomaly,Sentiment,Geo_risk
QBTS,1,LOW conviction (few signals),False,False,False,False,False,False,False,False,False,False,True,False,False,False


##### FILE: .\tests\test_breakout_retest.py #####
from core.breakout_retest_recognizer import BreakoutRetestRecognizer
from utils import data_fetcher

symbol = "AMZN"
price_df = data_fetcher.get_price_history(symbol, period="1y")
agent = BreakoutRetestRecognizer({
    "breakout_window": 15,
    "min_breakout_volume_ratio": 1.1,
    "gap_percent": 0.0})
result = agent.analyze(symbol, price_df)
print(result)
print(price_df.tail(15)[['date', 'high', 'close', 'volume']])

##### FILE: .\tests\test_breakout_screener.py #####
from core.breakout_retest_recognizer import BreakoutRetestRecognizer
from utils import data_fetcher
import time

tickers = [
    "SMCI", "NVDA", "META", "CELH", "TSLA", "ARM", "CAVA", "UBER",
    "AMD", "AVGO", "AAPL", "GOOG", "SHOP", "MSTR", "COIN", "DKNG",
    "NFLX", "PLTR", "CRWD", "TSM", "AMZN", "SOUN", "RIVN", "AI"
]

MIN_SCORE = 60
DAYS_AFTER_SIGNAL = 5   # בכמה ימים קדימה למדוד תשואה

agent = BreakoutRetestRecognizer({
    "breakout_window": 15,
    "min_breakout_volume_ratio": 1.1,
    "gap_percent": 0.0,
    "momentum_return": 0.2,
    "momentum_window": 7,
    "momentum_volume_ratio": 1.1
})

results = []

for symbol in tickers:
    try:
        price_df = data_fetcher.get_price_history(symbol, period="9mo")
        result = agent.analyze(symbol, price_df)
        if result["score"] >= MIN_SCORE:
            details = result["details"]
            # זיהוי breakout/momentum
            signal_type = None
            idx_signal = None
            price_signal = None
            date_signal = None

            # Breakout קלאסי
            for k, v in details.items():
                if k.startswith("breakout_") and v.get("breakout"):
                    idx_signal = v["breakout"]["idx"]
                    price_signal = v["breakout"]["price"]
                    date_signal = price_df.iloc[idx_signal]["date"]
                    signal_type = "Breakout"
                    break
            # Momentum breakout (אם אין קלאסי)
            if details.get("momentum_breakout"):
                idx_signal = price_df.index[-1]
                price_signal = price_df.iloc[-1]["close"]
                date_signal = price_df.iloc[-1]["date"]
                signal_type = "Momentum"

            # חישוב תשואה N ימים אחרי האיתות
            price_after = None
            ret_after = None
            if idx_signal is not None and (idx_signal + DAYS_AFTER_SIGNAL) < len(price_df):
                price_after = price_df.iloc[idx_signal + DAYS_AFTER_SIGNAL]["close"]
                ret_after = (price_after - price_signal) / price_signal * 100
            # Spike בנפח
            avg_vol = price_df['volume'].mean()
            vol_signal = price_df.iloc[idx_signal]["volume"] if idx_signal is not None else None
            volume_spike = vol_signal > avg_vol * 1.5 if vol_signal is not None else False

            results.append({
                "symbol": symbol,
                "score": result["score"],
                "signal_type": signal_type,
                "date": date_signal,
                "price": price_signal,
                "ret_after": round(ret_after, 2) if ret_after is not None else None,
                "volume_spike": volume_spike,
                "reason": result["explanation"].split(",")[0]
            })
        print(f"{symbol}: score={result['score']} | {result['explanation']}")
    except Exception as e:
        print(f"Error for {symbol}: {e}")
    time.sleep(1)

print(f"\n--- SIGNAL SUMMARY ({DAYS_AFTER_SIGNAL} days after signal) ---")
print("symbol | score | type | date | price | ret_after_% | vol_spike | reason")
for r in results:
    print(f"{r['symbol']} | {r['score']} | {r['signal_type']} | {r['date']} | {r['price']} | {r['ret_after']}% | {r['volume_spike']} | {r['reason']}")


##### FILE: .\tests\test_engine.py #####
from core.alpha_score_engine import AlphaScoreEngine
from utils import data_fetcher

symbol = "AAPL"  # אפשר להחליף לכל סימול אחר
price_df = data_fetcher.get_price_history(symbol, period="1y")
engine = AlphaScoreEngine()
result = engine.evaluate(symbol, price_df)
print(result)


##### FILE: .\tests\test_finnhub.py #####
import requests
import os

os.environ["FINNHUB_TOKEN"] = "d1in1ahr01qhbuvr1dggd1in1ahr01qhbuvr1dh0"

def test_finnhub(symbol):
    url = "https://finnhub.io/api/v1/stock/float"
    params = {
        "symbol": symbol,
        "token": os.getenv("FINNHUB_TOKEN")
    }
    r = requests.get(url, params=params, timeout=10)
    print(r.status_code)
    print(r.text)

test_finnhub("AAPL")


##### FILE: .\tests\test_parabolic_agent.py #####
from core.parabolic_agent import ParabolicAgent
from utils import data_fetcher

# בדוק טיקר חזק עם ריצות פראבוליות (למשל NVDA, TSLA, או אחר)
symbol = "NVDA"
price_df = data_fetcher.get_price_history(symbol, period="1y")
agent = ParabolicAgent()
result = agent.analyze(symbol, price_df)
print(f"=== ParabolicAgent | {symbol} ===")
print(result)

# בדוק גם טיקר בלי ריצה פראבולית ברורה
symbol2 = "KO"  # לדוג' קוקה קולה – לרוב דשדוש, פחות פראבולי
price_df2 = data_fetcher.get_price_history(symbol2, period="1y")
result2 = agent.analyze(symbol2, price_df2)
print(f"=== ParabolicAgent | {symbol2} ===")
print(result2)


##### FILE: .\tests\test_rsi_sniffer.py #####
import pandas as pd
from utils import data_fetcher
from core.rsi_sniffer import RSICompressionSniffer

symbol = "AAPL"
price_df = data_fetcher.get_price_history(symbol, period="1y")
sniffer = RSICompressionSniffer()
result = sniffer.analyze(symbol, price_df)
print(result)


##### FILE: .\tests\test_support_zone_strength.py #####
import os
import pandas as pd
import matplotlib.pyplot as plt
from utils import data_fetcher
from core.support_zone_strength_detector import SupportResistanceZoneStrengthDetector

def main():
    # 1. הכנות ותיקיה
    symbol = "NVDA"  # אפשר להחליף ל-TSLA וכו'
    if not os.path.exists("outputs"):
        os.makedirs("outputs")

    # 2. טען נתונים
    price_df = data_fetcher.get_price_history(symbol, period="1y")
    if price_df["date"].dtype == object or not pd.api.types.is_datetime64_any_dtype(price_df["date"]):
        price_df["date"] = pd.to_datetime(price_df["date"])

    # 3. הרץ סוכן
    agent = SupportResistanceZoneStrengthDetector({
        "window": 80,
        "min_touches": 2,
        "sensitivity": 0.012,
        "profile_radius": 0.012,
        "min_score": 30,
        "plot": False
    })
    result = agent.analyze(symbol, price_df)

    # 4. חלוקת תוצאות (חזקים/חלשים)
    supp_df = pd.DataFrame(result["support_zones"])
    res_df  = pd.DataFrame(result["resistance_zones"])

    min_score = agent.min_score
    supp_strong = supp_df[supp_df['score'] >= min_score]
    supp_weak   = supp_df[supp_df['score'] < min_score]
    res_strong  = res_df[res_df['score'] >= min_score]
    res_weak    = res_df[res_df['score'] < min_score]

    # 5. שמירה לאקסל עם 3 גליונות
    excel_path = "outputs/zones_results.xlsx"
    with pd.ExcelWriter(excel_path, engine="xlsxwriter") as writer:
        # אזורי תמיכה/התנגדות
        supp_df.to_excel(writer, sheet_name="Support Zones", index=False)
        res_df.to_excel(writer, sheet_name="Resistance Zones", index=False)

        # גליון Summary: סיכום + גרף
        summary_lines = [
            f"מספר אזורי תמיכה חזקים: {len(supp_strong)}",
            f"מספר אזורי תמיכה חלשים: {len(supp_weak)}",
            f"מספר אזורי התנגדות חזקים: {len(res_strong)}",
            f"מספר אזורי התנגדות חלשים: {len(res_weak)}",
            f"שמות מניה: {symbol}",
            f"תקופת ניתוח: {price_df['date'].min().date()} - {price_df['date'].max().date()}",
        ]
        summary_text = "\n".join(summary_lines)
        summary_df = pd.DataFrame({"Summary": [summary_text]})
        summary_df.to_excel(writer, sheet_name="Summary", index=False)

        # גרף
        fig, ax = plt.subplots(figsize=(12, 5))
        ax.plot(price_df['date'], price_df['close'], label='Close', color='black')
        for lvl in supp_strong['level']:
            ax.axhline(lvl, color='green', linestyle='--', alpha=0.7, label='Support')
        for lvl in res_strong['level']:
            ax.axhline(lvl, color='red', linestyle='--', alpha=0.7, label='Resistance')
        ax.set_title(f"סיכום רמות תמיכה/התנגדות ל-{symbol}")
        ax.set_xlabel('Date')
        ax.set_ylabel('Price')
        handles, labels = ax.get_legend_handles_labels()
        by_label = dict(zip(labels, handles))
        ax.legend(by_label.values(), by_label.keys())
        plt.tight_layout()
        plot_path = "outputs/zones_summary_plot.png"
        plt.savefig(plot_path)
        plt.close(fig)

        # הוסף את הגרף לגליון Summary
        worksheet = writer.sheets["Summary"]
        worksheet.insert_image('B4', plot_path)

    print(f"\nהקובץ outputs/zones_results.xlsx נוצר בהצלחה! כולל תמיכה/התנגדות וסיכום.")

if __name__ == "__main__":
    main()


##### FILE: .\tests\test_volume_tension.py #####
from core.volume_tension_meter import VolumeTensionMeter
from utils import data_fetcher

# בדיקה רגילה על טיקר "חזק"
symbol = "AAPL"
price_df = data_fetcher.get_price_history(symbol, period="1y")
agent = VolumeTensionMeter()
result = agent.analyze(symbol, price_df)
print("=== VolumeTensionMeter ULTIMATE |", symbol, "===")
print(result)

# בדיקת קצה: מניה בלי הרבה מסחר/נפח קטן
symbol2 = "GOVX"  # דוגמה למניה עם מעט מסחר, אפשר להחליף
price_df2 = data_fetcher.get_price_history(symbol2, period="1y")
result2 = agent.analyze(symbol2, price_df2)
print("=== VolumeTensionMeter ULTIMATE |", symbol2, "===")
print(result2)

# בדיקת קצה: פחות נתונים (תקופה קצרה)
symbol3 = "TSLA"
price_df3 = data_fetcher.get_price_history(symbol3, period="3mo")
result3 = agent.analyze(symbol3, price_df3)
print("=== VolumeTensionMeter ULTIMATE |", symbol3, "===")
print(result3)


##### FILE: .\utils\data_fetcher.py #####
import pandas as pd
import requests
import datetime
import yfinance as yf

TWELVEDATA_API_KEY = "1674fddb50d947cc97e7caafecd246a4"
FMP_API_KEY = "f8avXV34RWqtoYQXSZxVWrDlvhKCwIF5"

def get_price_history(symbol, period="12mo", interval="1d", source="auto"):
    """
    Fetch historical OHLCV data for a stock, choosing source (TwelveData, Yahoo).
    Args:
        symbol (str): e.g. "AAPL"
        period (str): e.g. "6mo", "12mo", "1y"
        interval (str): e.g. "1d", "1h"
        source (str): "auto" (default), "twelvedata", "yahoo"
    Returns:
        pd.DataFrame with columns [date, open, high, low, close, volume]
    """
    try:
        # Auto fallback: try TwelveData first, then Yahoo
        if source == "twelvedata" or source == "auto":
            intv = "1day" if interval == "1d" else interval
            outputsize = 250 if period == "12mo" else 120
            url = f"https://api.twelvedata.com/time_series"
            params = {
                "symbol": symbol,
                "interval": intv,
                "outputsize": outputsize,
                "apikey": TWELVEDATA_API_KEY
            }
            r = requests.get(url, params=params, verify=False)
            data = r.json()
            if "values" in data:
                df = pd.DataFrame(data["values"])
                df = df.rename(columns={"datetime": "date"})
                for col in ["open", "high", "low", "close", "volume"]:
                    df[col] = pd.to_numeric(df[col], errors="coerce")
                df = df.iloc[::-1].reset_index(drop=True)
                return df[["date", "open", "high", "low", "close", "volume"]]
            if source == "twelvedata":
                raise Exception(f"TwelveData error: {data}")

        # Fallback to yfinance (works always, no API key)
        if source == "yahoo" or source == "auto":
            df = yf.download(symbol, period=period, interval=interval, auto_adjust=True)
            if df.empty:
                return None
            df = df.reset_index()
            df.columns = [c.lower() for c in df.columns]
            # Ensure columns present
            df = df.rename(columns={"adj close": "close"})
            if "date" not in df.columns:
                df["date"] = df["index"] if "index" in df.columns else df.index
            return df[["date", "open", "high", "low", "close", "volume"]]
    except Exception as ex:
        print(f"Error fetching price history for {symbol}: {ex}")
        return None

def get_last_earnings_surprise(symbol):
    url = f"https://financialmodelingprep.com/api/v3/earnings-surprises/{symbol}?apikey={FMP_API_KEY}"
    r = requests.get(url, verify=False)
    data = r.json()
    if isinstance(data, list) and len(data) > 0:
        last = data[0]
        surprise = float(last.get("epsSurprise", 0))
        reported = float(last.get("eps", 0))
        estimate = float(last.get("epsEstimated", 0))
        surprise_pct = 0
        if estimate != 0:
            surprise_pct = 100 * (reported - estimate) / abs(estimate)
        return (surprise > 0, surprise_pct)
    return (False, None)

def get_growth_rate(symbol):
    url = f"https://financialmodelingprep.com/api/v3/income-statement/{symbol}?limit=5&apikey={FMP_API_KEY}"
    r = requests.get(url, verify=False)
    data = r.json()
    if isinstance(data, list) and len(data) > 1:
        revs = [float(x.get("revenue", 0)) for x in data[:5]]
        growth = 0
        try:
            growth = 100 * (revs[0] - revs[-1]) / abs(revs[-1]) if revs[-1] != 0 else 0
        except Exception:
            growth = 0
        return growth
    return 0

def get_pe_ratio(symbol):
    url = f"https://financialmodelingprep.com/api/v3/ratios-ttm/{symbol}?apikey={FMP_API_KEY}"
    r = requests.get(url, verify=False)
    data = r.json()
    if isinstance(data, list) and len(data) > 0:
        pe = float(data[0].get("peRatioTTM", 0))
    else:
        pe = None
    sector_pe = 20  # לשיפור: לשלוף אמיתי
    return pe, sector_pe

def get_sentiment_score(symbol):
    # דמו: ממוצע בין -1 ל-1, בפועל לשלוף מ-API ניוז
    import random
    return random.uniform(-1, 1)

def get_geo_risk_score(symbol):
    # דמו: בין 0 (אין סיכון) ל-1 (סיכון גבוה)
    import random
    return random.uniform(0, 1)


##### FILE: .\utils\finnhub_utils.py #####
# utils/finnhub_utils.py

import requests
import pandas as pd
import os

FINNHUB_API_KEY = os.getenv("FINNHUB_API_KEY", "d1in1ahr01qhbuvr1dggd1in1ahr01qhbuvr1dh0")

def fh_get(endpoint, params=None, verify_ssl=True):
    base_url = "https://finnhub.io/api/v1"
    url = f"{base_url}/{endpoint}"
    if params is None:
        params = {}
    params["token"] = FINNHUB_API_KEY

    try:
        response = requests.get(url, params=params, verify=verify_ssl, timeout=10)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        print(f"Finnhub error: {e}")
        return None

def fh_get_price_df(ticker, verify_ssl=True):
    try:
        url = f"https://finnhub.io/api/v1/stock/candle?symbol={ticker}&resolution=D&count=100&token={FINNHUB_API_KEY}"
        response = requests.get(url, verify=verify_ssl)
        data = response.json()

        if data.get("s") != "ok":
            print(f"Finnhub error: {data.get('s')}")
            return None

        df = pd.DataFrame({
            'date': pd.to_datetime(data['t'], unit='s'),
            'open': data['o'],
            'high': data['h'],
            'low': data['l'],
            'close': data['c'],
            'volume': data['v']
        })
        df.set_index('date', inplace=True)
        df.name = ticker
        return df
    except Exception as e:
        print(f"❌ fh_get_price_df error for {ticker}: {e}")
        return None

def fh_get_float_ratio(ticker, verify_ssl=True):
    # לא באמת קיים API פתוח לנתון הזה – מחזיר None כרגע
    return None


##### FILE: .\utils\fix_cert.py #####
import certifi
print(certifi.where())


##### FILE: .\utils\fmp_utils.py #####
# utils/fmp_utils.py

import requests
import pandas as pd
import os

FMP_API_KEY = os.getenv("FMP_API_KEY", "f8avXV34RWqtoYQXSZxVWrDlvhKCwIF5")

def fmp_get(endpoint, params=None, verify_ssl=True):
    base_url = "https://financialmodelingprep.com/api/v3"
    url = f"{base_url}/{endpoint}"
    if params is None:
        params = {}
    params["apikey"] = FMP_API_KEY

    try:
        response = requests.get(url, params=params, verify=verify_ssl, timeout=10)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        print(f"FMP error: {e}")
        return None

def fmp_get_price_df(ticker, verify_ssl=True):
    try:
        url = f"https://financialmodelingprep.com/api/v3/historical-price-full/{ticker}?apikey={FMP_API_KEY}&serietype=line"
        response = requests.get(url, verify=verify_ssl)
        if response.status_code != 200:
            print(f"FMP error: HTTP {response.status_code}")
            return None

        data = response.json()
        if 'historical' not in data:
            print("FMP error: 'historical' key missing")
            return None

        df = pd.DataFrame(data['historical'])
        df['date'] = pd.to_datetime(df['date'])
        df.set_index('date', inplace=True)
        df = df.sort_index()
        df.name = ticker
        return df
    except Exception as e:
        print(f"❌ fmp_get_price_df error for {ticker}: {e}")
        return None

def fmp_get_float_ratio(ticker, verify_ssl=True):
    # נתוני float ratio לא תמיד זמינים. מחזיר None כברירת מחדל.
    return None


##### FILE: .\utils\twelve_utils.py #####
# utils/twelve_utils.py

import requests
import pandas as pd
import os

TWELVE_API_KEY = os.getenv("TWELVE_API_KEY", "1674fddb50d947cc97e7caafecd246a4")

def td_get(endpoint, params=None, verify_ssl=True):
    base_url = "https://api.twelvedata.com"
    url = f"{base_url}/{endpoint}"
    if params is None:
        params = {}
    params["apikey"] = TWELVE_API_KEY

    try:
        response = requests.get(url, params=params, verify=verify_ssl, timeout=10)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        print(f"TwelveData error: {e}")
        return None

def td_get_price_df(ticker, verify_ssl=True):
    data = td_get("time_series", {
        "symbol": ticker,
        "interval": "1day",
        "outputsize": 100
    }, verify_ssl=verify_ssl)

    if data is None or "values" not in data:
        return None

    df = pd.DataFrame(data["values"])
    df["datetime"] = pd.to_datetime(df["datetime"])
    df.set_index("datetime", inplace=True)
    df = df.astype(float)
    df = df.rename(columns={
        "open": "open",
        "high": "high",
        "low": "low",
        "close": "close",
        "volume": "volume"
    })
    df.sort_index(inplace=True)
    df.name = ticker
    return df

def td_get_float_ratio(ticker, verify_ssl=True):
    # TwelveData לא באמת מספק נתון float ratio. מוחזר None.
    return None
