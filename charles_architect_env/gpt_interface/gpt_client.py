import os
import fitz  # PyMuPDF
import openpyxl
from openai import OpenAI
from openai import OpenAIError
from dotenv import load_dotenv

# ×˜×¢×Ÿ ××©×ª× ×™ ×¡×‘×™×‘×” ××”×§×•×‘×¥ .env
load_dotenv()

# ×™×¦×™×¨×ª ×œ×§×•×— OpenAI ×¢× ×”××¤×ª×— ××”Ö¾.env
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


def load_context_from_documents(folder_path="project_docs", max_chars=12000):
    """
    ×˜×•×¢×Ÿ ×ª×•×›×Ÿ ××›×œ ×”××¡××›×™× ×”× ×ª××›×™× ×‘×ª×™×§×™×™×” (PDF, Excel, TXT)
    """
    context_text = ""

    for filename in os.listdir(folder_path):
        filepath = os.path.join(folder_path, filename)
        ext = filename.lower().split(".")[-1]

        try:
            if ext == "txt":
                with open(filepath, "r", encoding="utf-8") as f:
                    content = f.read()
                    context_text += f"\n\nğŸ“„ {filename}:\n" + content

            elif ext == "pdf":
                with fitz.open(filepath) as doc:
                    text = "\n".join(page.get_text() for page in doc)
                    context_text += f"\n\nğŸ“„ {filename} (PDF):\n" + text

            elif ext in ["xlsx", "xls"]:
                wb = openpyxl.load_workbook(filepath, data_only=True)
                for sheet in wb.sheetnames:
                    sheet_obj = wb[sheet]
                    rows = []
                    for row in sheet_obj.iter_rows(values_only=True):
                        line = "\t".join([str(cell) if cell is not None else "" for cell in row])
                        rows.append(line)
                    context_text += f"\n\nğŸ“Š {filename} â€“ ×’×œ×™×•×Ÿ {sheet}:\n" + "\n".join(rows[:20])  # ×¨×§ 20 ×©×•×¨×•×ª ×¨××©×•× ×•×ª

        except Exception as e:
            context_text += f"\nâš ï¸ ×©×’×™××” ×‘×§×¨×™××ª {filename}: {str(e)}\n"

    return context_text[:max_chars]


def ask_gpt(prompt: str):
    """
    ×©×•××œ ××ª GPT ×©××œ×” ×¢× ×§×•× ×˜×§×¡×˜ ××•×ª×× ××™×©×™ ××”××¡××›×™×
    """
    system_prompt = (
        "××ª×” Charles_Architect â€“ GPT ××•××—×” ×œ×¤×™×ª×•×— ××¢×¨×›×•×ª AI ××ª×§×“××•×ª ×œ×–×™×”×•×™ ×× ×™×•×ª ×¤×•×¨×¦×•×ª. "
        "×”××˜×¨×” ×©×œ×š ×”×™× ×œ×”×›×™×¨ ××ª ×”××¢×¨×›×ª ×©Ö¾×¨×Ÿ ×‘×•× ×”, ×œ×œ××•×“ ××ª ×›×œ ×”××¡××›×™× ×•×”×§×‘×¦×™×, ×•×œ×™×™×¢×¥, ×œ×‘× ×•×ª ×§×•×“, ×œ×”×¦×™×¢ ×ª×©×ª×™×ª, ×•×œ×—×©×•×‘ ×§×“×™××”. "
        "×¢× ×” ×‘×¢×‘×¨×™×ª ×‘×¨×•×¨×”, ×©×œ×‘Ö¾××—×¨×™Ö¾×©×œ×‘, ×›××™×œ×• ××ª×” ×©×•×ª×£ ×‘×¦×•×•×ª. ×›×œ ×©××œ×” ×ª×ª×™×™×—×¡ ×ª××™×“ ×œ×§×•× ×˜×§×¡×˜ ×©× ×˜×¢×Ÿ ××”××¡××›×™× ×©×œ ×”××¢×¨×›×ª."
    )

    context = load_context_from_documents()
    full_prompt = f"{context}\n\nğŸ” ×©××œ×”:\n{prompt}"

    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": full_prompt}
            ],
            temperature=0.4,
            max_tokens=1000
        )
        return response.choices[0].message.content.strip()

    except OpenAIError as e:
        return f"×©×’×™××” ×‘×‘×§×©×ª GPT: {str(e)}"
